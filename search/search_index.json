{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Project Mu \u00b6 Project Mu is a modular adaptation of TianoCore's edk2 tuned for building modern devices using a scalable, maintainable, and reusable pattern. Mu is built around the idea that shipping and maintaining a UEFI product is an ongoing collaboration between numerous partners. For too long the industry has built products using a \"forking\" model combined with copy/paste/rename and with each new product the maintenance burden grows to such a level that updates are near impossible due to cost and risk. Project Mu also tries to address the complex business relationships and legal challenges facing partners today. To build most products it often requires both closed-source, proprietary assets as well as open source and industry standard code. The distributed build system and multi-repository design allow product teams to keep code separate and connected to their original source while respecting legal and business boundaries. Project Mu originated from building modern Windows PCs but its patterns and design allow it to be scaled down or up for whatever the final product's intent. IoT, Server, PC, or any other form factor should be able to leverage the content. Primary Goals \u00b6 Initially, this project will focus on two central goals. Share our active code tree to both solicit feedback and entice partners to collaborate \u00b6 Project Mu is an active project. This is not a side project, mirror, clone, or example. This is the same code used today on many of Microsoft's 1 st party devices and it will be kept current because it must be to continue to enable shipping products. Promote, evangelize, and support an industry shift to a more collaborative environment so we all can build and maintain products with lower costs and higher quality \u00b6 Today's open source projects although extremely valuable are very resource intensive to interact with. This friction leads to major industry players avoiding public interaction thus diminishing the overall community\u2019s value. The modern era of open source projects has incorporated new tools and procedures to lower this friction and it is our goal to leverage those tools. GitHub provides issue tracking, Pull Requests, Gated builds, tracked/required web-based code reviews, and CI/CD (Continuous builds and testing). It is our belief that by leveraging and extending this automation and workflow we can lower the friction and foster a safe place for all contributors to work. Guiding Principles \u00b6 Less is More * Be open to change / flexible - Keep learning. If it was easy this would have been solved before Design for code reuse Leverage tools / invest in automation Navigation \u00b6 Have a look around this site to see what is Project Mu. Start by reviewing the details of the community and our process. See how to interact and get involved, why it's different, how to work within or extend it, as well as where everything is located. Finally, explore the Developer Docs if you want to review more in-depth details. Having trouble? \u00b6 Skim the FAQ Road map \u00b6 After the first few months of Mu, our initial roadmap is largely complete. Any remaining items have been moved to the GitHub Issues and will continue to be tracked there. We hope to use GitHub Issues to track new roadmap items going forwards. Project Mu GitHub Issues Join Us \u00b6 Contact info and additional methods to collaborate coming soon. Code of conduct \u00b6 This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Reporting Issues \u00b6 Short answer: Open a github issue. More details: Contributing Contributing \u00b6 Short answer: Open a pull request. More details: Contributing License \u00b6 Refer to License Documentation Build Information Version: 0.8.0 Build Time: 2019-10-21 20:05","title":"Home"},{"location":"#welcome-to-project-mu","text":"Project Mu is a modular adaptation of TianoCore's edk2 tuned for building modern devices using a scalable, maintainable, and reusable pattern. Mu is built around the idea that shipping and maintaining a UEFI product is an ongoing collaboration between numerous partners. For too long the industry has built products using a \"forking\" model combined with copy/paste/rename and with each new product the maintenance burden grows to such a level that updates are near impossible due to cost and risk. Project Mu also tries to address the complex business relationships and legal challenges facing partners today. To build most products it often requires both closed-source, proprietary assets as well as open source and industry standard code. The distributed build system and multi-repository design allow product teams to keep code separate and connected to their original source while respecting legal and business boundaries. Project Mu originated from building modern Windows PCs but its patterns and design allow it to be scaled down or up for whatever the final product's intent. IoT, Server, PC, or any other form factor should be able to leverage the content.","title":"Welcome to Project Mu"},{"location":"#primary-goals","text":"Initially, this project will focus on two central goals.","title":"Primary Goals"},{"location":"#share-our-active-code-tree-to-both-solicit-feedback-and-entice-partners-to-collaborate","text":"Project Mu is an active project. This is not a side project, mirror, clone, or example. This is the same code used today on many of Microsoft's 1 st party devices and it will be kept current because it must be to continue to enable shipping products.","title":"Share our active code tree to both solicit feedback and entice partners to collaborate"},{"location":"#promote-evangelize-and-support-an-industry-shift-to-a-more-collaborative-environment-so-we-all-can-build-and-maintain-products-with-lower-costs-and-higher-quality","text":"Today's open source projects although extremely valuable are very resource intensive to interact with. This friction leads to major industry players avoiding public interaction thus diminishing the overall community\u2019s value. The modern era of open source projects has incorporated new tools and procedures to lower this friction and it is our goal to leverage those tools. GitHub provides issue tracking, Pull Requests, Gated builds, tracked/required web-based code reviews, and CI/CD (Continuous builds and testing). It is our belief that by leveraging and extending this automation and workflow we can lower the friction and foster a safe place for all contributors to work.","title":"Promote, evangelize, and support an industry shift to a more collaborative environment so we all can build and maintain products with lower costs and higher quality"},{"location":"#guiding-principles","text":"Less is More * Be open to change / flexible - Keep learning. If it was easy this would have been solved before Design for code reuse Leverage tools / invest in automation","title":"Guiding Principles"},{"location":"#navigation","text":"Have a look around this site to see what is Project Mu. Start by reviewing the details of the community and our process. See how to interact and get involved, why it's different, how to work within or extend it, as well as where everything is located. Finally, explore the Developer Docs if you want to review more in-depth details.","title":"Navigation"},{"location":"#having-trouble","text":"Skim the FAQ","title":"Having trouble?"},{"location":"#road-map","text":"After the first few months of Mu, our initial roadmap is largely complete. Any remaining items have been moved to the GitHub Issues and will continue to be tracked there. We hope to use GitHub Issues to track new roadmap items going forwards. Project Mu GitHub Issues","title":"Road map"},{"location":"#join-us","text":"Contact info and additional methods to collaborate coming soon.","title":"Join Us"},{"location":"#code-of-conduct","text":"This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"Code of conduct"},{"location":"#reporting-issues","text":"Short answer: Open a github issue. More details: Contributing","title":"Reporting Issues"},{"location":"#contributing","text":"Short answer: Open a pull request. More details: Contributing","title":"Contributing"},{"location":"#license","text":"Refer to License Documentation Build Information Version: 0.8.0 Build Time: 2019-10-21 20:05","title":"License"},{"location":"faq/","text":"FAQ \u00b6 Purpose/Goals \u00b6 How is this related to TianoCore? \u00b6 As you can probably tell, Project Mu is based on TianoCore . It represents a variant of TianoCore that was customized within Microsoft for scaling and maintainability. It's not exactly a staging branch for TianoCore, as there are some changes that may not have application within or meet the explicit goals of that project, but it is a place where features and changes can be publicly featured and discussed. So, is this a fork? \u00b6 Not entirely. It is our goal to continue to treat TianoCore as a true upstream. Our release branches will always be based on the latest stable TianoCore release, and we will always try to PR viable fixes and features into the TianoCore project. What is it? Where is it going? \u00b6 Project Mu is a product of the Microsoft Core UEFI team and is the basis for the system firmware within a number of Microsoft products. It will continue to be maintained to reflect the FW practices and features leveraged for the best experience with Windows and other Microsoft products. A secondary purpose is to engage with the community, both in TianoCore and the industry at large. We hope that Project Mu serves as a concrete example for discussing different approaches to managing the challenges faced by the UEFI ecosystem. Content/Structure \u00b6 Is this really following \"Less is More\"? \u00b6 Yes. The idea is lowering the entanglement of code, lowering the coupling, and allowing the product to pick and choose the code it needs. This means when building any given product, you don't need all the Project Mu code. Why are there so many repos? \u00b6 Project Mu makes liberal use of multiple repositories due to the mixture of requirements in the UEFI ecosystem. Some repos are split for technical reasons, some for organizational, and some for legal. For details, see \"Repo Philosophy\" in What and Why .","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#purposegoals","text":"","title":"Purpose/Goals"},{"location":"faq/#how-is-this-related-to-tianocore","text":"As you can probably tell, Project Mu is based on TianoCore . It represents a variant of TianoCore that was customized within Microsoft for scaling and maintainability. It's not exactly a staging branch for TianoCore, as there are some changes that may not have application within or meet the explicit goals of that project, but it is a place where features and changes can be publicly featured and discussed.","title":"How is this related to TianoCore?"},{"location":"faq/#so-is-this-a-fork","text":"Not entirely. It is our goal to continue to treat TianoCore as a true upstream. Our release branches will always be based on the latest stable TianoCore release, and we will always try to PR viable fixes and features into the TianoCore project.","title":"So, is this a fork?"},{"location":"faq/#what-is-it-where-is-it-going","text":"Project Mu is a product of the Microsoft Core UEFI team and is the basis for the system firmware within a number of Microsoft products. It will continue to be maintained to reflect the FW practices and features leveraged for the best experience with Windows and other Microsoft products. A secondary purpose is to engage with the community, both in TianoCore and the industry at large. We hope that Project Mu serves as a concrete example for discussing different approaches to managing the challenges faced by the UEFI ecosystem.","title":"What is it? Where is it going?"},{"location":"faq/#contentstructure","text":"","title":"Content/Structure"},{"location":"faq/#is-this-really-following-less-is-more","text":"Yes. The idea is lowering the entanglement of code, lowering the coupling, and allowing the product to pick and choose the code it needs. This means when building any given product, you don't need all the Project Mu code.","title":"Is this really following \"Less is More\"?"},{"location":"faq/#why-are-there-so-many-repos","text":"Project Mu makes liberal use of multiple repositories due to the mixture of requirements in the UEFI ecosystem. Some repos are split for technical reasons, some for organizational, and some for legal. For details, see \"Repo Philosophy\" in What and Why .","title":"Why are there so many repos?"},{"location":"license/","text":"Licensing for Project Mu \u00b6 Project Mu has numerous repositories. Each of these can have different licenses depending on the content and partner but in general we want OSS friendly licenses. For this documentation we use the following license. License \u00b6 BSD 2-Clause License Copyright \u00a9 Microsoft All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"license/#licensing-for-project-mu","text":"Project Mu has numerous repositories. Each of these can have different licenses depending on the content and partner but in general we want OSS friendly licenses. For this documentation we use the following license.","title":"Licensing for Project Mu"},{"location":"license/#license","text":"BSD 2-Clause License Copyright \u00a9 Microsoft All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"CodeDevelopment/compile/","text":"How to Build/Compile \u00b6 The repository/product/project should describe any unique steps required. Project Mu currently supports two methods of building. Those will be described here to encourage pattern/code reuse and limit the required repository specific documentation. Compile Testing aka Mu_Build \u00b6 Mu_Build is a framework for running a battery of tests against a single Mu repository (and its dependencies). A plugin model is used for adding additional tests. Today one such plugin is a basic compile test. The repository maintainer may add additional tests such as linters, etc. It is often desirable to compile test code and at times there might not be a product to test with. This is also how the Pull Requests gates are implemented and enforced. Note This also runs the other static code tests so it does more than compile. Assumption is that the repository to compile has been cloned to your filesystem and is in the state ready to compile. Open cmd prompt at workspace root Suggestion: Activate your python virtual environment Install or update Python dependencies using pip Run Mu_Build to: Clone code dependencies Download binary dependencies Statically test code Compile test code mu_build - c < Mu Repo Build Config File > - p < 1 st Mu Pkg Build Config File > < 2 nd Mu Pkg Build Config File ... > Open TestResults.xml for results Open log files to debug any errors Project Build aka PlatformBuild \u00b6 Info There is currently no example in Project Mu. An example platform is in the works! When you actually want to compile for a platform that will create a firmware binary which can be flashed and execute on a platform this process is necessary. open cmd prompt at workspace root Suggestion: Activate your python virtual environment Install or update Python dependencies using pip Locate the PlatformBuild.py file (generally in the platform build dir) Run PlatformBuild.py Other features \u00b6 PlatformBuild.py leverages a common UefiBuild python component. This component provides a common set of features. The UefiBuild component documentation is published from the mu_pip_environment repository but here are a few of the common features developers find useful. Control the target of the build. Pass Target = RELEASE Build a single module: BuildModule = MdePkg / ModuleToBuild . inf Build with reporting: Single report type BUILDREPORTING = TRUE BUILDREPORT_TYPES = \"PCD\" Change report file BUILDREPORT_FILE = filename . txt default is BUILD_REPORT.TXT All report types. BUILDREPORTING = TRUE BUILDREPORT_TYPES = \"PCD DEPEX FLASH BUILD_FLAGS LIBRARY\" Clean build: --clean Clean only (no compile): --cleanonly Skip some of the build steps: Skip the Edk2 build step: --skipbuild Skip pre or post build steps: --skipprebuild or --skippostbuild Change a Build variable that is used in Edk2 build process: BLD_ * _DEBUG_OUTPUT_LEVEL = 0 x80000004 will be passed to DSC/FDF as DEBUG_OUTPUT_LEVEL . These variable names and behavior are platform defined. BLD_ * _ < var name > is used for builds of any target type unless there is a more specific version for the given target type. BLD_DEBUG_ < var name > is used for debug builds only BLD_RELEASE_ < var name > is used for release builds only Using a config file. To simplify calling of PlatformBuild.py if there is a BuildConfig.conf in the root of your UEFI workspace those parameters will be used as well. The command line overrides anything from the conf file. Example BuildConfig.conf \u00b6 # Turn on full build reports BUILDREPORTING = TRUE BUILDREPORT_TYPES = \"PCD DEPEX FLASH BUILD_FLAGS LIBRARY\"","title":"Compiling"},{"location":"CodeDevelopment/compile/#how-to-buildcompile","text":"The repository/product/project should describe any unique steps required. Project Mu currently supports two methods of building. Those will be described here to encourage pattern/code reuse and limit the required repository specific documentation.","title":"How to Build/Compile"},{"location":"CodeDevelopment/compile/#compile-testing-aka-mu_build","text":"Mu_Build is a framework for running a battery of tests against a single Mu repository (and its dependencies). A plugin model is used for adding additional tests. Today one such plugin is a basic compile test. The repository maintainer may add additional tests such as linters, etc. It is often desirable to compile test code and at times there might not be a product to test with. This is also how the Pull Requests gates are implemented and enforced. Note This also runs the other static code tests so it does more than compile. Assumption is that the repository to compile has been cloned to your filesystem and is in the state ready to compile. Open cmd prompt at workspace root Suggestion: Activate your python virtual environment Install or update Python dependencies using pip Run Mu_Build to: Clone code dependencies Download binary dependencies Statically test code Compile test code mu_build - c < Mu Repo Build Config File > - p < 1 st Mu Pkg Build Config File > < 2 nd Mu Pkg Build Config File ... > Open TestResults.xml for results Open log files to debug any errors","title":"Compile Testing aka Mu_Build"},{"location":"CodeDevelopment/compile/#project-build-aka-platformbuild","text":"Info There is currently no example in Project Mu. An example platform is in the works! When you actually want to compile for a platform that will create a firmware binary which can be flashed and execute on a platform this process is necessary. open cmd prompt at workspace root Suggestion: Activate your python virtual environment Install or update Python dependencies using pip Locate the PlatformBuild.py file (generally in the platform build dir) Run PlatformBuild.py","title":"Project Build aka PlatformBuild"},{"location":"CodeDevelopment/compile/#other-features","text":"PlatformBuild.py leverages a common UefiBuild python component. This component provides a common set of features. The UefiBuild component documentation is published from the mu_pip_environment repository but here are a few of the common features developers find useful. Control the target of the build. Pass Target = RELEASE Build a single module: BuildModule = MdePkg / ModuleToBuild . inf Build with reporting: Single report type BUILDREPORTING = TRUE BUILDREPORT_TYPES = \"PCD\" Change report file BUILDREPORT_FILE = filename . txt default is BUILD_REPORT.TXT All report types. BUILDREPORTING = TRUE BUILDREPORT_TYPES = \"PCD DEPEX FLASH BUILD_FLAGS LIBRARY\" Clean build: --clean Clean only (no compile): --cleanonly Skip some of the build steps: Skip the Edk2 build step: --skipbuild Skip pre or post build steps: --skipprebuild or --skippostbuild Change a Build variable that is used in Edk2 build process: BLD_ * _DEBUG_OUTPUT_LEVEL = 0 x80000004 will be passed to DSC/FDF as DEBUG_OUTPUT_LEVEL . These variable names and behavior are platform defined. BLD_ * _ < var name > is used for builds of any target type unless there is a more specific version for the given target type. BLD_DEBUG_ < var name > is used for debug builds only BLD_RELEASE_ < var name > is used for release builds only Using a config file. To simplify calling of PlatformBuild.py if there is a BuildConfig.conf in the root of your UEFI workspace those parameters will be used as well. The command line overrides anything from the conf file.","title":"Other features"},{"location":"CodeDevelopment/compile/#example-buildconfigconf","text":"# Turn on full build reports BUILDREPORTING = TRUE BUILDREPORT_TYPES = \"PCD DEPEX FLASH BUILD_FLAGS LIBRARY\"","title":"Example BuildConfig.conf"},{"location":"CodeDevelopment/overview/","text":"Code Development Overview \u00b6 Tools \u00b6 First you will need to setup your UEFI development environment. Project Mu leverages most of the tools from TianoCore EDK2 . We have streamlined the process for the tool chains and systems we use but our project's goals are to support various tool chains and development environments. For the best experience or for those new to UEFI and Project Mu we have provided guidance in our prerequisites page. Code \u00b6 Next you will need to clone a repository or set of repositories to work on. For core work (Project Mu Repos) you can clone the desired repo, make your changes, run CI builds, run your tests, and submit a PR. For platform work (outside of Project Mu) you will need to clone the platform repository and then follow the platform setup process. See details on the compile page for more information about CI builds and how to compile a package or platform. Code should follow best practices. We are working to add some best practices on the requirements page. We also attempt to enforce these best practices thru our CI build process. Tests \u00b6 One area of focus for Project Mu is on testing. Firmware testing has traditionally been hard and very manual. We hope to describe techniques and provide resources to make this easier and more automated. Testing needs to be part of the code development process. Check out the testing page for more details.","title":"Overview"},{"location":"CodeDevelopment/overview/#code-development-overview","text":"","title":"Code Development Overview"},{"location":"CodeDevelopment/overview/#tools","text":"First you will need to setup your UEFI development environment. Project Mu leverages most of the tools from TianoCore EDK2 . We have streamlined the process for the tool chains and systems we use but our project's goals are to support various tool chains and development environments. For the best experience or for those new to UEFI and Project Mu we have provided guidance in our prerequisites page.","title":"Tools"},{"location":"CodeDevelopment/overview/#code","text":"Next you will need to clone a repository or set of repositories to work on. For core work (Project Mu Repos) you can clone the desired repo, make your changes, run CI builds, run your tests, and submit a PR. For platform work (outside of Project Mu) you will need to clone the platform repository and then follow the platform setup process. See details on the compile page for more information about CI builds and how to compile a package or platform. Code should follow best practices. We are working to add some best practices on the requirements page. We also attempt to enforce these best practices thru our CI build process.","title":"Code"},{"location":"CodeDevelopment/overview/#tests","text":"One area of focus for Project Mu is on testing. Firmware testing has traditionally been hard and very manual. We hope to describe techniques and provide resources to make this easier and more automated. Testing needs to be part of the code development process. Check out the testing page for more details.","title":"Tests"},{"location":"CodeDevelopment/prerequisites/","text":"Prerequisites for building Code \u00b6 Generally there are a set of tools required on the platform. Project Mu tries to minimize the number of global tools but there are a few. There could be more depending on the repository/product/platform you are building but this should get you started. If the repo requires other tools those should be documented within the repo. The tools also vary by Operating System and Compiler choice. Project Mu will document what is currently supported but the expectation is that between Project Mu and TianoCore Edk2 you could use any of those tool sets. Windows \u00b6 Python \u00b6 Download latest Python from https://www.python.org/downloads https : // www . python . org / ftp / python / 3 . 7 . 4 / python - 3 . 7 . 4 - amd64 . exe It is recommended you use the following options when installing python: include pip support include test support Git \u00b6 Download latest Git For Windows from https://git-scm.com/download/win https : // github . com / git - for - windows / git / releases / download / v2 . 20 . 1 . windows . 1 / Git - 2 . 20 . 1 - 64 - bit . exe It is recommended you use the following options: Checkout as is, commit as is. Native Channel support (this will help in corp environments) Check the box to \"Enable Git Credential Manager\" Visual Studio 2017 \u00b6 Download latest version of VS build Tools to c:\\TEMP https : // aka . ms / vs / 15 / release / vs_buildtools . exe Install from cmd line with required features (this set will change overtime). C :\\ TEMP \\ vs_buildtools . exe -- quiet -- wait -- norestart -- nocache -- installPath C :\\ BuildTools -- add Microsoft . VisualStudio . Component . VC . CoreBuildTools -- add Microsoft . VisualStudio . Component . VC . Tools . x86 . x64 -- add Microsoft . VisualStudio . Component . Windows10SDK . 17763 -- add Microsoft . VisualStudio . Component . VC . Tools . ARM -- add Microsoft . VisualStudio . Component . VC . Tools . ARM64 See component list here for more options. https://docs.microsoft.com/en-us/visualstudio/install/workload-component-id-vs-build-tools?view=vs-2017 Visual Studio 2019 Early Support \u00b6 Download latest version of VS build Tools to c:\\TEMP https : // aka . ms / vs / 16 / release / vs_buildtools . exe Install from cmd line with required features (this set will change over time). C :\\ TEMP \\ vs_buildtools . exe -- quiet -- wait -- norestart -- nocache -- installPath C :\\ BuildTools -- add Microsoft . VisualStudio . Component . VC . CoreBuildTools -- add Microsoft . VisualStudio . Component . VC . Tools . x86 . x64 -- add Microsoft . VisualStudio . Component . Windows10SDK . 17763 -- add Microsoft . VisualStudio . Component . VC . Tools . ARM -- add Microsoft . VisualStudio . Component . VC . Tools . ARM64 See component list here for more options. https://docs.microsoft.com/en-us/visualstudio/install/workload-component-id-vs-build-tools?view=vs-2019 Optional - Windows Driver Kit \u00b6 Provides Inf2Cat.exe, needed to prepare Windows firmware update packages for signing . Download the WDK installer https : // go . microsoft . com / fwlink / ? linkid = 2085767 Install from cmd line with required features (this set will change over time). wdksetup . exe / features OptionId . WindowsDriverKitComplete / q Optional - Create an Omnicache \u00b6 An Omnicache is a Project Mu tool that leverages git features to speed up git update operations. This helps speed up git operations if you have multiple workspaces by using the git \"--reference\" feature. Omnicache is documented in the Mu Pip Environment section of this site. Windows Subsystem For Linux (WSL) \u00b6 Coming soon All Operating Systems - Python Virtual Environment and Mu Build Tools \u00b6 In all Operating Systems environments the Project Mu Build tools are needed. Python virtual environments are strongly suggested especially when doing development in multiple workspaces. Each workspace should have its own virtual environment as to not modify the global system state. Since Project Mu uses Pip modules this allows each workspace to keep the versions in sync with the workspace requirements. More info on Python Virtual Environments: https://docs.python.org/3/library/venv.html Workspace Virtual Environment Setup Process \u00b6 A sample directory layout of workspaces and Python Virtual Environments: \u00b6 code |-- edk2 |-- env_dev <--- env for Mu Dev |-- env_docs <--- env for Mu Docs |-- env_edk <--- env for TianoCore |-- env_local <--- env for - e installations of mu_pip / edk2tool |-- Omnicache |-- Palindrome |-- Palindrome2 Do this one time per workspace Open Cmd Prompt in the directory where you want to store your virtual environment. A directory adjacent to workspace directories is convenient. run python cmd python - m venv < your virtual env name > Activate it for your session. Activate Virtual Environment \u00b6 Do this each time you open a new command window to build your workspace. Open Cmd Prompt run activate script - for windows cmd prompt (cmd.exe) do this < your virtual env name > \\ Script \\ activate cd into your workspace directory Update/Install your python pip requirements. This is generally at the workspace root. pip install --upgrade -r requirements.txt Do dev work and run your builds! More About Project Mu tools using Pip \u00b6 Project Mu currently has 3 pip modules mu_python_library \u00b6 UEFI, Edk2, Acpi, and TPM common library functions. python - m pip install --upgrade mu_python_library mu_environment \u00b6 Self Describing Environment (SDE) code which is used to organize and coordinate UEFI builds. This is the Project Mu Build system, plugin manager, edk2 build wrapper, logging, etc. python - m pip install --upgrade mu_environment mu_build \u00b6 CI and package test scripts. Supports compiling as well as running other build test plugins. python - m pip install --upgrade mu_build","title":"Tools and Prerequisite"},{"location":"CodeDevelopment/prerequisites/#prerequisites-for-building-code","text":"Generally there are a set of tools required on the platform. Project Mu tries to minimize the number of global tools but there are a few. There could be more depending on the repository/product/platform you are building but this should get you started. If the repo requires other tools those should be documented within the repo. The tools also vary by Operating System and Compiler choice. Project Mu will document what is currently supported but the expectation is that between Project Mu and TianoCore Edk2 you could use any of those tool sets.","title":"Prerequisites for building Code"},{"location":"CodeDevelopment/prerequisites/#windows","text":"","title":"Windows"},{"location":"CodeDevelopment/prerequisites/#python","text":"Download latest Python from https://www.python.org/downloads https : // www . python . org / ftp / python / 3 . 7 . 4 / python - 3 . 7 . 4 - amd64 . exe It is recommended you use the following options when installing python: include pip support include test support","title":"Python"},{"location":"CodeDevelopment/prerequisites/#git","text":"Download latest Git For Windows from https://git-scm.com/download/win https : // github . com / git - for - windows / git / releases / download / v2 . 20 . 1 . windows . 1 / Git - 2 . 20 . 1 - 64 - bit . exe It is recommended you use the following options: Checkout as is, commit as is. Native Channel support (this will help in corp environments) Check the box to \"Enable Git Credential Manager\"","title":"Git"},{"location":"CodeDevelopment/prerequisites/#visual-studio-2017","text":"Download latest version of VS build Tools to c:\\TEMP https : // aka . ms / vs / 15 / release / vs_buildtools . exe Install from cmd line with required features (this set will change overtime). C :\\ TEMP \\ vs_buildtools . exe -- quiet -- wait -- norestart -- nocache -- installPath C :\\ BuildTools -- add Microsoft . VisualStudio . Component . VC . CoreBuildTools -- add Microsoft . VisualStudio . Component . VC . Tools . x86 . x64 -- add Microsoft . VisualStudio . Component . Windows10SDK . 17763 -- add Microsoft . VisualStudio . Component . VC . Tools . ARM -- add Microsoft . VisualStudio . Component . VC . Tools . ARM64 See component list here for more options. https://docs.microsoft.com/en-us/visualstudio/install/workload-component-id-vs-build-tools?view=vs-2017","title":"Visual Studio 2017"},{"location":"CodeDevelopment/prerequisites/#visual-studio-2019-early-support","text":"Download latest version of VS build Tools to c:\\TEMP https : // aka . ms / vs / 16 / release / vs_buildtools . exe Install from cmd line with required features (this set will change over time). C :\\ TEMP \\ vs_buildtools . exe -- quiet -- wait -- norestart -- nocache -- installPath C :\\ BuildTools -- add Microsoft . VisualStudio . Component . VC . CoreBuildTools -- add Microsoft . VisualStudio . Component . VC . Tools . x86 . x64 -- add Microsoft . VisualStudio . Component . Windows10SDK . 17763 -- add Microsoft . VisualStudio . Component . VC . Tools . ARM -- add Microsoft . VisualStudio . Component . VC . Tools . ARM64 See component list here for more options. https://docs.microsoft.com/en-us/visualstudio/install/workload-component-id-vs-build-tools?view=vs-2019","title":"Visual Studio 2019 Early Support"},{"location":"CodeDevelopment/prerequisites/#optional-windows-driver-kit","text":"Provides Inf2Cat.exe, needed to prepare Windows firmware update packages for signing . Download the WDK installer https : // go . microsoft . com / fwlink / ? linkid = 2085767 Install from cmd line with required features (this set will change over time). wdksetup . exe / features OptionId . WindowsDriverKitComplete / q","title":"Optional - Windows Driver Kit"},{"location":"CodeDevelopment/prerequisites/#optional-create-an-omnicache","text":"An Omnicache is a Project Mu tool that leverages git features to speed up git update operations. This helps speed up git operations if you have multiple workspaces by using the git \"--reference\" feature. Omnicache is documented in the Mu Pip Environment section of this site.","title":"Optional - Create an Omnicache"},{"location":"CodeDevelopment/prerequisites/#windows-subsystem-for-linux-wsl","text":"Coming soon","title":"Windows Subsystem For Linux (WSL)"},{"location":"CodeDevelopment/prerequisites/#all-operating-systems-python-virtual-environment-and-mu-build-tools","text":"In all Operating Systems environments the Project Mu Build tools are needed. Python virtual environments are strongly suggested especially when doing development in multiple workspaces. Each workspace should have its own virtual environment as to not modify the global system state. Since Project Mu uses Pip modules this allows each workspace to keep the versions in sync with the workspace requirements. More info on Python Virtual Environments: https://docs.python.org/3/library/venv.html","title":"All Operating Systems - Python Virtual Environment and Mu Build Tools"},{"location":"CodeDevelopment/prerequisites/#workspace-virtual-environment-setup-process","text":"","title":"Workspace Virtual Environment Setup Process"},{"location":"CodeDevelopment/prerequisites/#a-sample-directory-layout-of-workspaces-and-python-virtual-environments","text":"code |-- edk2 |-- env_dev <--- env for Mu Dev |-- env_docs <--- env for Mu Docs |-- env_edk <--- env for TianoCore |-- env_local <--- env for - e installations of mu_pip / edk2tool |-- Omnicache |-- Palindrome |-- Palindrome2 Do this one time per workspace Open Cmd Prompt in the directory where you want to store your virtual environment. A directory adjacent to workspace directories is convenient. run python cmd python - m venv < your virtual env name > Activate it for your session.","title":"A sample directory layout of workspaces and Python Virtual Environments:"},{"location":"CodeDevelopment/prerequisites/#activate-virtual-environment","text":"Do this each time you open a new command window to build your workspace. Open Cmd Prompt run activate script - for windows cmd prompt (cmd.exe) do this < your virtual env name > \\ Script \\ activate cd into your workspace directory Update/Install your python pip requirements. This is generally at the workspace root. pip install --upgrade -r requirements.txt Do dev work and run your builds!","title":"Activate Virtual Environment"},{"location":"CodeDevelopment/prerequisites/#more-about-project-mu-tools-using-pip","text":"Project Mu currently has 3 pip modules","title":"More About Project Mu tools using Pip"},{"location":"CodeDevelopment/prerequisites/#mu_python_library","text":"UEFI, Edk2, Acpi, and TPM common library functions. python - m pip install --upgrade mu_python_library","title":"mu_python_library"},{"location":"CodeDevelopment/prerequisites/#mu_environment","text":"Self Describing Environment (SDE) code which is used to organize and coordinate UEFI builds. This is the Project Mu Build system, plugin manager, edk2 build wrapper, logging, etc. python - m pip install --upgrade mu_environment","title":"mu_environment"},{"location":"CodeDevelopment/prerequisites/#mu_build","text":"CI and package test scripts. Supports compiling as well as running other build test plugins. python - m pip install --upgrade mu_build","title":"mu_build"},{"location":"CodeDevelopment/requirements/","text":"Requirements for contributing Source Code \u00b6 Basics \u00b6 Make sure it follows the package, repo, and codebase rules Make sure it builds Write a unit test for it. Test positive cases as well as negative cases. Make sure it has docs. Even a minimal readme.md will get collected and added to the docs. Make sure it has only valid characters encoded (often copy paste from Microsoft Word docs or the internet will lead to invalid characters) If it is a small change/tweak to existing code that originates outside of Project Mu please mark it with //MUCHANGE Uefi Package \u00b6 UEFI Components \u00b6 All new modules must be listed in their containing package DSC in the components section All modules must follow the dependency rules of their containing package All modules within common layers should avoid silicon or architecture dependencies. Use existing libraries and functionality when possible Build out minimal required abstraction to allow other silicon or architectures to leverage common capabilities Public Header files \u00b6 Don't include other header files Don't mix public and private information in the same header file Implementation details should be contained to the instance Use \"doxygen\" style function header comments to clearly specify parameters and return results. Use a guidgen tool to define any guids For libraries: Library class should be listed in Package DEC file A NULL instance must be created that allows compiling and linking with minimal dependencies. Library Instance \u00b6 The supported module types in the INFs must be accurate. LIBRARY_CLASS : < Library Class Name >|< Module types supported by this instance > Use STATIC on each non-public function and non-public global to avoid conflicts with other modules. Use EFIAPI on all public library class functions. More info \u00b6 For general Edk2 and UEFI development additional information can be found at the TianoCore.org website.","title":"Code Requirements"},{"location":"CodeDevelopment/requirements/#requirements-for-contributing-source-code","text":"","title":"Requirements for contributing Source Code"},{"location":"CodeDevelopment/requirements/#basics","text":"Make sure it follows the package, repo, and codebase rules Make sure it builds Write a unit test for it. Test positive cases as well as negative cases. Make sure it has docs. Even a minimal readme.md will get collected and added to the docs. Make sure it has only valid characters encoded (often copy paste from Microsoft Word docs or the internet will lead to invalid characters) If it is a small change/tweak to existing code that originates outside of Project Mu please mark it with //MUCHANGE","title":"Basics"},{"location":"CodeDevelopment/requirements/#uefi-package","text":"","title":"Uefi Package"},{"location":"CodeDevelopment/requirements/#uefi-components","text":"All new modules must be listed in their containing package DSC in the components section All modules must follow the dependency rules of their containing package All modules within common layers should avoid silicon or architecture dependencies. Use existing libraries and functionality when possible Build out minimal required abstraction to allow other silicon or architectures to leverage common capabilities","title":"UEFI Components"},{"location":"CodeDevelopment/requirements/#public-header-files","text":"Don't include other header files Don't mix public and private information in the same header file Implementation details should be contained to the instance Use \"doxygen\" style function header comments to clearly specify parameters and return results. Use a guidgen tool to define any guids For libraries: Library class should be listed in Package DEC file A NULL instance must be created that allows compiling and linking with minimal dependencies.","title":"Public Header files"},{"location":"CodeDevelopment/requirements/#library-instance","text":"The supported module types in the INFs must be accurate. LIBRARY_CLASS : < Library Class Name >|< Module types supported by this instance > Use STATIC on each non-public function and non-public global to avoid conflicts with other modules. Use EFIAPI on all public library class functions.","title":"Library Instance"},{"location":"CodeDevelopment/requirements/#more-info","text":"For general Edk2 and UEFI development additional information can be found at the TianoCore.org website.","title":"More info"},{"location":"CodeDevelopment/test/","text":"Tests \u00b6 Testing firmware is hard. Lets just stop there. If you want to read on please do at your own risk. Project Mu supports a few types of testing and this page will help provide some high level info and links for more information. Static Code Tests (analysis) \u00b6 Mu_Build provides a framework for running static tests on the code base. Simple tests like character encoding are examples. In Project Mu we are working to expand this set of tests to include checking guids, checking for library classes, etc. UEFI Shell Based Unit Tests \u00b6 UEFI Shell Based Functional Tests \u00b6 UEFI Shell Based Audit Tests \u00b6 Testing Python \u00b6 Create pytest and/or python unit-test compatible tests. Make sure the python code passes the flake8 \"linter\"","title":"Testing"},{"location":"CodeDevelopment/test/#tests","text":"Testing firmware is hard. Lets just stop there. If you want to read on please do at your own risk. Project Mu supports a few types of testing and this page will help provide some high level info and links for more information.","title":"Tests"},{"location":"CodeDevelopment/test/#static-code-tests-analysis","text":"Mu_Build provides a framework for running static tests on the code base. Simple tests like character encoding are examples. In Project Mu we are working to expand this set of tests to include checking guids, checking for library classes, etc.","title":"Static Code Tests (analysis)"},{"location":"CodeDevelopment/test/#uefi-shell-based-unit-tests","text":"","title":"UEFI Shell Based Unit Tests"},{"location":"CodeDevelopment/test/#uefi-shell-based-functional-tests","text":"","title":"UEFI Shell Based Functional Tests"},{"location":"CodeDevelopment/test/#uefi-shell-based-audit-tests","text":"","title":"UEFI Shell Based Audit Tests"},{"location":"CodeDevelopment/test/#testing-python","text":"Create pytest and/or python unit-test compatible tests. Make sure the python code passes the flake8 \"linter\"","title":"Testing Python"},{"location":"DeveloperDocs/attribution/","text":"Documentation framework attribution \u00b6 A special thank you to the people and projects that helped make Project Mu Documentation possible. Projects \u00b6 Mkdocs \u00b6 https://www.mkdocs.org/ MkDocs License (BSD) Copyright \u00a9 2014, Tom Christie. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. mkdocs macros plugin \u00b6 https://github.com/fralau/mkdocs_macros_plugin MIT License Copyright (C) 2018 Laurent Franceschetti Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Material for MkDocs \u00b6 https://squidfunk.github.io/mkdocs-material/ License MIT License Copyright \u00a9 2016 - 2017 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. PyMdown Extensions \u00b6 https://facelessuser.github.io/pymdown-extensions/ PyMdown Extensions The MIT License (MIT) (Except where stated below) Copyright \u00a9 2014 - 2018 Isaac Muse Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Doc Framework Attribution"},{"location":"DeveloperDocs/attribution/#documentation-framework-attribution","text":"A special thank you to the people and projects that helped make Project Mu Documentation possible.","title":"Documentation framework attribution"},{"location":"DeveloperDocs/attribution/#projects","text":"","title":"Projects"},{"location":"DeveloperDocs/attribution/#mkdocs","text":"https://www.mkdocs.org/ MkDocs License (BSD) Copyright \u00a9 2014, Tom Christie. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Mkdocs"},{"location":"DeveloperDocs/attribution/#mkdocs-macros-plugin","text":"https://github.com/fralau/mkdocs_macros_plugin MIT License Copyright (C) 2018 Laurent Franceschetti Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"mkdocs macros plugin"},{"location":"DeveloperDocs/attribution/#material-for-mkdocs","text":"https://squidfunk.github.io/mkdocs-material/ License MIT License Copyright \u00a9 2016 - 2017 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Material for MkDocs"},{"location":"DeveloperDocs/attribution/#pymdown-extensions","text":"https://facelessuser.github.io/pymdown-extensions/ PyMdown Extensions The MIT License (MIT) (Except where stated below) Copyright \u00a9 2014 - 2018 Isaac Muse Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"PyMdown Extensions"},{"location":"DeveloperDocs/build_community_docs/","text":"Building Community Docs \u00b6 Info Today this process has been validated for use on Windows 10. This setup process is expected to roughly the same on other operating systems and none of the actual documentation source or tools should have any OS dependency. Get the docs repository \u00b6 First, you need to clone the project mu docs repository. git clone https : // github . com / Microsoft / mu . git Install required tools \u00b6 Install python (Current suggested version is 3.7.x). Current min requirement is python 3.4+. Checkout python.org for directions. Install pip. Generally, this is done when installing python but can also be done as its own process. Details here https://pip.pypa.io/en/stable/installing/#do-i-need-to-install-pip Update pip. python - m pip install --upgrade pip Install dependencies. pip install --upgrade -r requirements.txt if wanting to use spell check Install nodejs from https://nodejs.org/en/ Install cspell npm install - g cspell Install Git on your path (Required for generating dynamic repo based content during preprocess) General Suggested documentation workflow \u00b6 open two command windows at the root of docs repository Window 1: Use to serve files locally Use mkdocs serve Any changes from the DocBuild process will be picked up and served Window 2: Use to preprocess the source repo files Run the DocBuild.py command from this window Make changes to the docs in source repos or this repo and then re-run the DocBuild.py build command Pre-process with dynamic content from source repo(s) \u00b6 Create \"repos\" folder (somewhere outside of workspace) Clone all repositories for dynamic content here Set each repo to the branch/commit that you want to document run the DocBuild.py command supplying the parameters DocBuild . py --clean --build --OutputDir docs --yml mkdocs_base.yml --RootDir ..\\repos Pre-process with no source repo(s) content \u00b6 run the DocBuild.py command supplying minimal parameters DocBuild . py --clean --build --yml mkdocs_base.yml Clean / Remove all pre-processed content \u00b6 use DocBuild.py command DocBuild . py --clean --yml <path to yml base file> --OutputDir <docs folder> Check for character encoding issues \u00b6 navigate to root of repository (should see a docs folder, the mkdocs_base.yml file, and a few other things) open command window run Utf8Test python script cmd prompt Utf8Test . py --RootDir docs should complete with no errors Note Note you can also run it on any dynamic content by using a different RootDir parameter. Use -h for usage to get more detailed information of any failures Use mkdocs to build the docs \u00b6 navigate to root of repository (should see a docs folder, the mkdocs_base.yml file, and a few other things) open command window run mkdocs build from cmd prompt at root mkdocs build - s - v should complete with no errors Spell check the docs \u00b6 navigate to root of repository (should see a docs folder, the mkdocs_base.yml file, and a few other things) open command window run command to spell check cspell docs /**/ * . md should complete with no errors False Spelling Errors If the spelling error is a false positive there are two solutions: If it is a valid word or commonly understood term then add the word to the cspell.json config file words section Update the cspell.json file ignorePaths element to ignore the entire file. Locally serve the docs \u00b6 One great feature of mkdocs is how easy it is to locally serve the docs to validate your changes. Use mkdocs to serve your local copy mkdocs serve navigate to 127.0.0.1:8000 in web browser Important If you get an error like Config file 'mkdocs.yml' does not exist you must run the preprocess step. Advanced doc features \u00b6 We do turn on a few advanced/extension features. Please use these carefully as they may break compatibility if the publishing engine is changed. Checkout the sample syntax / test page for syntax and information.","title":"How To Build"},{"location":"DeveloperDocs/build_community_docs/#building-community-docs","text":"Info Today this process has been validated for use on Windows 10. This setup process is expected to roughly the same on other operating systems and none of the actual documentation source or tools should have any OS dependency.","title":"Building Community Docs"},{"location":"DeveloperDocs/build_community_docs/#get-the-docs-repository","text":"First, you need to clone the project mu docs repository. git clone https : // github . com / Microsoft / mu . git","title":"Get the docs repository"},{"location":"DeveloperDocs/build_community_docs/#install-required-tools","text":"Install python (Current suggested version is 3.7.x). Current min requirement is python 3.4+. Checkout python.org for directions. Install pip. Generally, this is done when installing python but can also be done as its own process. Details here https://pip.pypa.io/en/stable/installing/#do-i-need-to-install-pip Update pip. python - m pip install --upgrade pip Install dependencies. pip install --upgrade -r requirements.txt if wanting to use spell check Install nodejs from https://nodejs.org/en/ Install cspell npm install - g cspell Install Git on your path (Required for generating dynamic repo based content during preprocess)","title":"Install required tools"},{"location":"DeveloperDocs/build_community_docs/#general-suggested-documentation-workflow","text":"open two command windows at the root of docs repository Window 1: Use to serve files locally Use mkdocs serve Any changes from the DocBuild process will be picked up and served Window 2: Use to preprocess the source repo files Run the DocBuild.py command from this window Make changes to the docs in source repos or this repo and then re-run the DocBuild.py build command","title":"General Suggested documentation workflow"},{"location":"DeveloperDocs/build_community_docs/#pre-process-with-dynamic-content-from-source-repos","text":"Create \"repos\" folder (somewhere outside of workspace) Clone all repositories for dynamic content here Set each repo to the branch/commit that you want to document run the DocBuild.py command supplying the parameters DocBuild . py --clean --build --OutputDir docs --yml mkdocs_base.yml --RootDir ..\\repos","title":"Pre-process with dynamic content from source repo(s)"},{"location":"DeveloperDocs/build_community_docs/#pre-process-with-no-source-repos-content","text":"run the DocBuild.py command supplying minimal parameters DocBuild . py --clean --build --yml mkdocs_base.yml","title":"Pre-process with no source repo(s) content"},{"location":"DeveloperDocs/build_community_docs/#clean-remove-all-pre-processed-content","text":"use DocBuild.py command DocBuild . py --clean --yml <path to yml base file> --OutputDir <docs folder>","title":"Clean / Remove all pre-processed content"},{"location":"DeveloperDocs/build_community_docs/#check-for-character-encoding-issues","text":"navigate to root of repository (should see a docs folder, the mkdocs_base.yml file, and a few other things) open command window run Utf8Test python script cmd prompt Utf8Test . py --RootDir docs should complete with no errors Note Note you can also run it on any dynamic content by using a different RootDir parameter. Use -h for usage to get more detailed information of any failures","title":"Check for character encoding issues"},{"location":"DeveloperDocs/build_community_docs/#use-mkdocs-to-build-the-docs","text":"navigate to root of repository (should see a docs folder, the mkdocs_base.yml file, and a few other things) open command window run mkdocs build from cmd prompt at root mkdocs build - s - v should complete with no errors","title":"Use mkdocs to build the docs"},{"location":"DeveloperDocs/build_community_docs/#spell-check-the-docs","text":"navigate to root of repository (should see a docs folder, the mkdocs_base.yml file, and a few other things) open command window run command to spell check cspell docs /**/ * . md should complete with no errors False Spelling Errors If the spelling error is a false positive there are two solutions: If it is a valid word or commonly understood term then add the word to the cspell.json config file words section Update the cspell.json file ignorePaths element to ignore the entire file.","title":"Spell check the docs"},{"location":"DeveloperDocs/build_community_docs/#locally-serve-the-docs","text":"One great feature of mkdocs is how easy it is to locally serve the docs to validate your changes. Use mkdocs to serve your local copy mkdocs serve navigate to 127.0.0.1:8000 in web browser Important If you get an error like Config file 'mkdocs.yml' does not exist you must run the preprocess step.","title":"Locally serve the docs"},{"location":"DeveloperDocs/build_community_docs/#advanced-doc-features","text":"We do turn on a few advanced/extension features. Please use these carefully as they may break compatibility if the publishing engine is changed. Checkout the sample syntax / test page for syntax and information.","title":"Advanced doc features"},{"location":"DeveloperDocs/developer_docs/","text":"Developer Docs \u00b6 Philosophy \u00b6 Documentation is critical. There is a steep learning curve in UEFI and no amount of documentation will change that, but at a minimum quick, clear, and easy documentation can help everyone adopt features faster and with higher confidence. Our documentation system will focus on making this an easy, low friction, and collaborative process. The pull request process will eventually compel developers to submit documentation whenever they submit new components and refactoring. Documentation will be done in markdown as this has the benefit of being easily readable in both plain text as well as transformed into a richer experience. It also is quick to learn and to write. Currently, we leverage mkdocs as our publishing engine but since all content is in markdown it could be transitioned to another engine without significant reinvestment. Community documentation \u00b6 This content is documented in static markdown files within the Project Mu repository. We leverage mkdocs to generate web-hosted content on every change and host these using github.io. These static files focus on how the project and community interact. We strongly encourage contribution and follow the standard PR model for all changes, big and small. Developer documentation \u00b6 This content is documented in a couple of ways. There are static markdown files in the Project Mu repository. This contains details about high level concepts, howto articles, and features of the project and all repos within Project Mu. Examples: Code layout, git usage, tools, building, packaging, etc. There is repo and package level documentation for features. These are also static markdown files but these are contained within the repo that contains the feature. A \u201cdocs\u201d folder for each repo and each package will host this content. Changes will also follow the standard PR model for the containing repo. Next, there is feature and instance documentation. This should inform a developer interested in the implementation specifics of what this module is and what additional requirements it has including code dependencies and limitations. This should be documented in markdown files located with the component. These should be updated whenever the component is updated and should be part of a code PR. Finally, for API and traditional functional documentation, our current stance is this is required in code (public APIs) but the published documentation (doxygen html, pdf, etc) is not necessary. Code tools like vscode already provide a lower friction method to index, find def, and search that uses this content directly embedded in the code.","title":"Overview"},{"location":"DeveloperDocs/developer_docs/#developer-docs","text":"","title":"Developer Docs"},{"location":"DeveloperDocs/developer_docs/#philosophy","text":"Documentation is critical. There is a steep learning curve in UEFI and no amount of documentation will change that, but at a minimum quick, clear, and easy documentation can help everyone adopt features faster and with higher confidence. Our documentation system will focus on making this an easy, low friction, and collaborative process. The pull request process will eventually compel developers to submit documentation whenever they submit new components and refactoring. Documentation will be done in markdown as this has the benefit of being easily readable in both plain text as well as transformed into a richer experience. It also is quick to learn and to write. Currently, we leverage mkdocs as our publishing engine but since all content is in markdown it could be transitioned to another engine without significant reinvestment.","title":"Philosophy"},{"location":"DeveloperDocs/developer_docs/#community-documentation","text":"This content is documented in static markdown files within the Project Mu repository. We leverage mkdocs to generate web-hosted content on every change and host these using github.io. These static files focus on how the project and community interact. We strongly encourage contribution and follow the standard PR model for all changes, big and small.","title":"Community documentation"},{"location":"DeveloperDocs/developer_docs/#developer-documentation","text":"This content is documented in a couple of ways. There are static markdown files in the Project Mu repository. This contains details about high level concepts, howto articles, and features of the project and all repos within Project Mu. Examples: Code layout, git usage, tools, building, packaging, etc. There is repo and package level documentation for features. These are also static markdown files but these are contained within the repo that contains the feature. A \u201cdocs\u201d folder for each repo and each package will host this content. Changes will also follow the standard PR model for the containing repo. Next, there is feature and instance documentation. This should inform a developer interested in the implementation specifics of what this module is and what additional requirements it has including code dependencies and limitations. This should be documented in markdown files located with the component. These should be updated whenever the component is updated and should be part of a code PR. Finally, for API and traditional functional documentation, our current stance is this is required in code (public APIs) but the published documentation (doxygen html, pdf, etc) is not necessary. Code tools like vscode already provide a lower friction method to index, find def, and search that uses this content directly embedded in the code.","title":"Developer documentation"},{"location":"DeveloperDocs/doc_sample_test/","text":"Documentation Sample / Test file / Advanced doc features \u00b6 mkdocs macros plugin \u00b6 This plugin allows providing some variables in mkdocs.yml file and then reference those variables using jinja2 syntax in md files. Most of these variables are populated and created during the DocBuild step and inserted into the yml file. https://github.com/fralau/mkdocs_macros_plugin Material theme \u00b6 This theme provides the skin for the site. This also provides capabilities thru plugins. https://squidfunk.github.io/mkdocs-material/ Markdown Extensions \u00b6 The Material theme supports markdown extensions. Check the yml file for what extensions are currently on. Below is more specific info. https://squidfunk.github.io/mkdocs-material/extensions/permalinks/ https://squidfunk.github.io/mkdocs-material/extensions/pymdown/ Admonition plugin \u00b6 This plugin in combo with the material theme provides great looking ways for doc developers to highlight parts of their message. Please check out: https://squidfunk.github.io/mkdocs-material/extensions/admonition/ for the capabilities and syntax. One example: Note Sample note here. emoji support \u00b6 Who doesn't love using emojis. Icon usage has shown to help communicate directions and cross language barriers. https://facelessuser.github.io/pymdown-extensions/extensions/emoji/ Twitter, github, and emojione tags available. Others \u00b6 Check out the mkdocs.yml file for other extensions and details can be found in the links above.","title":"Sample Syntax"},{"location":"DeveloperDocs/doc_sample_test/#documentation-sample-test-file-advanced-doc-features","text":"","title":"Documentation Sample / Test file / Advanced doc features"},{"location":"DeveloperDocs/doc_sample_test/#mkdocs-macros-plugin","text":"This plugin allows providing some variables in mkdocs.yml file and then reference those variables using jinja2 syntax in md files. Most of these variables are populated and created during the DocBuild step and inserted into the yml file. https://github.com/fralau/mkdocs_macros_plugin","title":"mkdocs macros plugin"},{"location":"DeveloperDocs/doc_sample_test/#material-theme","text":"This theme provides the skin for the site. This also provides capabilities thru plugins. https://squidfunk.github.io/mkdocs-material/","title":"Material theme"},{"location":"DeveloperDocs/doc_sample_test/#markdown-extensions","text":"The Material theme supports markdown extensions. Check the yml file for what extensions are currently on. Below is more specific info. https://squidfunk.github.io/mkdocs-material/extensions/permalinks/ https://squidfunk.github.io/mkdocs-material/extensions/pymdown/","title":"Markdown Extensions"},{"location":"DeveloperDocs/doc_sample_test/#admonition-plugin","text":"This plugin in combo with the material theme provides great looking ways for doc developers to highlight parts of their message. Please check out: https://squidfunk.github.io/mkdocs-material/extensions/admonition/ for the capabilities and syntax. One example: Note Sample note here.","title":"Admonition plugin"},{"location":"DeveloperDocs/doc_sample_test/#emoji-support","text":"Who doesn't love using emojis. Icon usage has shown to help communicate directions and cross language barriers. https://facelessuser.github.io/pymdown-extensions/extensions/emoji/ Twitter, github, and emojione tags available.","title":"emoji support"},{"location":"DeveloperDocs/doc_sample_test/#others","text":"Check out the mkdocs.yml file for other extensions and details can be found in the links above.","title":"Others"},{"location":"DeveloperDocs/requirements/","text":"Requirements for contributing documentation \u00b6 Conventions and lessons learned \u00b6 Please update this list as you learn more. filenames should all be lowercase. filenames should use \"_\" to separate words and should not have spaces. all links to pages are case sensitive (when published to GitHub the server is case sensitive) use a code editor like vscode for markdown. It has linting support and will identify issues prior to build. If you markdown has images: Awesome. Images help make docs more informative and easier to understand Path in markdown to image must be relative Suggested to put in same directory as md file image filename must end with _mu. extension . Example my_image_name_mu.png Supported image extensions are gif, jpg, png","title":"Documentation Requirements"},{"location":"DeveloperDocs/requirements/#requirements-for-contributing-documentation","text":"","title":"Requirements for contributing documentation"},{"location":"DeveloperDocs/requirements/#conventions-and-lessons-learned","text":"Please update this list as you learn more. filenames should all be lowercase. filenames should use \"_\" to separate words and should not have spaces. all links to pages are case sensitive (when published to GitHub the server is case sensitive) use a code editor like vscode for markdown. It has linting support and will identify issues prior to build. If you markdown has images: Awesome. Images help make docs more informative and easier to understand Path in markdown to image must be relative Suggested to put in same directory as md file image filename must end with _mu. extension . Example my_image_name_mu.png Supported image extensions are gif, jpg, png","title":"Conventions and lessons learned"},{"location":"How/contributing/","text":"How to contribute \u00b6 There are three common ways to contribute. Participate in discussions using GitHub issues. Contribute documentation by opening a GitHub Pull Request. Contribute code by opening a GitHub Pull Request Issue Tracker Usage \u00b6 https://github.com/Microsoft/mu/issues General feedback and discussions \u00b6 Please start a discussion on the issue tracker. Bugs and feature requests \u00b6 For non-security related bugs please log a new issue on the Project Mu repo issue tracker . The best way to get your bug fixed is to be as detailed as you can be about the problem. Providing a code snippet or sample driver that exposes the issue with steps to reproduce the problem is ideal. Reporting security issues and bugs \u00b6 Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) secure@microsoft.com . You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the Security TechCenter . Contributions of Documentation and/or Code \u00b6 Pull Requests \u00b6 If you don't know what a pull request is read this article: https://help.github.com/articles/about-pull-requests . Make sure the repository can build and all tests pass. Familiarize yourself with the project workflow and our coding conventions. General workflow \u00b6 Fork Repository in GitHub Make desired changes. Build it, test it, document it Submit a Pull Request back to the development branch you would like to target. You will be asked to digitally sign a CLA The server will run some builds and tests and report status Community and reviewers will provide feedback in the Pull Request Make changes / adjust based on feedback and discussion Keep your PR branch in-sync with the branch you are targeting and resolve any merge conflicts Once the the PR status is all passing it can be squashed and merged (just press the button in the PR). If the PR is ready the maintainers may complete it for you. That is it. Thanks for contributing. More details on : Code Development Tests Development Documentation Development Contributor License Agreement (CLA) \u00b6 This project welcomes contributions and suggestions. Most (code and documentation) contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com . When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.","title":"Contributing"},{"location":"How/contributing/#how-to-contribute","text":"There are three common ways to contribute. Participate in discussions using GitHub issues. Contribute documentation by opening a GitHub Pull Request. Contribute code by opening a GitHub Pull Request","title":"How to contribute"},{"location":"How/contributing/#issue-tracker-usage","text":"https://github.com/Microsoft/mu/issues","title":"Issue Tracker Usage"},{"location":"How/contributing/#general-feedback-and-discussions","text":"Please start a discussion on the issue tracker.","title":"General feedback and discussions"},{"location":"How/contributing/#bugs-and-feature-requests","text":"For non-security related bugs please log a new issue on the Project Mu repo issue tracker . The best way to get your bug fixed is to be as detailed as you can be about the problem. Providing a code snippet or sample driver that exposes the issue with steps to reproduce the problem is ideal.","title":"Bugs and feature requests"},{"location":"How/contributing/#reporting-security-issues-and-bugs","text":"Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) secure@microsoft.com . You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the Security TechCenter .","title":"Reporting security issues and bugs"},{"location":"How/contributing/#contributions-of-documentation-andor-code","text":"","title":"Contributions of Documentation and/or Code"},{"location":"How/contributing/#pull-requests","text":"If you don't know what a pull request is read this article: https://help.github.com/articles/about-pull-requests . Make sure the repository can build and all tests pass. Familiarize yourself with the project workflow and our coding conventions.","title":"Pull Requests"},{"location":"How/contributing/#general-workflow","text":"Fork Repository in GitHub Make desired changes. Build it, test it, document it Submit a Pull Request back to the development branch you would like to target. You will be asked to digitally sign a CLA The server will run some builds and tests and report status Community and reviewers will provide feedback in the Pull Request Make changes / adjust based on feedback and discussion Keep your PR branch in-sync with the branch you are targeting and resolve any merge conflicts Once the the PR status is all passing it can be squashed and merged (just press the button in the PR). If the PR is ready the maintainers may complete it for you. That is it. Thanks for contributing. More details on : Code Development Tests Development Documentation Development","title":"General workflow"},{"location":"How/contributing/#contributor-license-agreement-cla","text":"This project welcomes contributions and suggestions. Most (code and documentation) contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com . When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.","title":"Contributor License Agreement (CLA)"},{"location":"How/release_process/","text":"Overview \u00b6 Contents and Process Under Active Development The basics of this process are identical to those followed by the Project Mu firmware integration and release process internal to Microsoft, but the formal documentation, branch naming, and tagging process is a work in progress. While this is how we expect things to work, there may be changes within the the first few releases driven by feedback within the team and any external consumers/contributors. In the interest of maintaining a close, well-defined relationship with the upstream project, TianoCore, the active release branch of Project Mu is periodically deprecated and all Mu-related changes are rebased onto a selected commit of TianoCore. This keeps Project Mu up to date with TianoCore while highlighting all Project Mu differences in the most recent commits and encouraging the reverse integration of all changes/fixes back into TianoCore In general, the life-cycle of active code follows the following path: All active work in Project Mu is performed on a release /* branch, named sequentially according to the date of TianoCore commit that it's based on (e.g. release / 201808 is based on the edk2 - stable201808 branch in TianoCore). Work proceeds on that branch until a new TianoCore integration is targeted, at which point a new branch is created and all existing changes are rebased onto the new branch and the new branch is used for all active development going forward. At this point, the previous branch enters a stabilization period where further tests are performed and only bug fixes are allowed to be committed. After stabilization, the branch is labeled as stable and will only receive critical bug fixes either directly to the branch or backported from a more recent release. release /* branches will be maintained in LTS (Long-Term Support) for at least the next two releases. The below diagram illustrates the life-cycle of a single branch and indicates the critical points in its lifetime. These critical points will be applied as tags for reference and documentation. The tags are given a name relative to the target branch and consist of: Upstream base, Rebase complete, Rebase builds, Rebase boots, RCn, and Stable. These tags are discussed in more detail below. Important Due to the impacts of the rebase process on the history of Mu release branches, any downstream consumers will have to follow a similar integration process when upgrading to a new release. Any custom changes made within the Project Mu repos will have to be rebased from one release to the next. This is why we strongly discourage forking Project Mu for direct modification (ie. consumption, not contribution). Instead, leverage the distributed repo management system and override management system to integrate proprietary code/modules. Current Branch Status \u00b6 While the earliest release branches may not be included in this process, starting with release / 201903 and going forwards the status of each branch will be recorded in the README.rst file at the root of the branch. In general, the README found in Basecore will contain information that is common to all of the Mu submodules, but each submodule will also have its own README for each release branch that contains notes specific to the development that occurs in that submodule during a release cycle. The README will also contain a summary of the branch status at a given time. For example, here is a sample status for Basecore release / 201903 as of the time of this writing: Current Phase: Development Entered Current Phase: 2019/03/25 Planned Exit Date: May 2019 Upstream Integration Phase \u00b6 At this time, we are targeting upstream integrations for roughly once a quarter, attempting to align 1:1 with the TianoCore stable release cadence. Prior to an integration, the status dashboard (not yet created) will be updated with the target date of completion and the target TianoCore commit and/or release. For example, a plan was made to transition off of release / 20180529 when TianoCore announced the edk2 - stable201808 release. Once a commit is selected, a set of rebase commits will be chosen from the active (previous) release /* branch. Ideally, these commits would include everything from the previous rebase through the most recent * _RC tag. For example, when moving from the release / 201808 branch, the commits will be selected from 1808 _Upstream (not inclusive) tag to 1808 _RC1 . After selection, this list of commits will be evaluated to determine whether any changes are no longer needed in the Mu history. The most likely causes of this action are: A change was submitted to TianoCore and has been accepted since the last rebase. Therefore, the change is no longer needed in Mu history. A change was reverted or modified more recently in Mu history, and the history of this change was squashed to maintain simplicity when comparing with upstream (TianoCore). Once all evaluation is completed, the rebase will be performed in the new release /* branch. This branch will then be built for a reference platform (to be selected by internal team) and booted, at which point it will be considered the active development branch. Integration Milestone Tags \u00b6 During integration, multiple tags are applied to the branch to serve as milestones. They also serve as reference point for changelog documentation that is produced during the integration process. These tags are described below: * _Upstream This tag is placed on the exact TianoCore commit that a given release branch started from. This is used as a reference point between branches and relative to the rebase operation. The documentation produced for this tag contains the differences in TianoCore between this branch and the previous branch. For branches that originated from TianoCore releases, this changelog should be identical to the TianoCore changelog. * _Rebase This tag is placed on the commit at the branch HEAD once the rebase is completed. The only changes to the commits from the last branch should be merge conflict resolutions and any history simplification as described above. The documentation produced for this tag contains a record of these resolutions and simplifications. * _RefBuild This tag is placed on the commit where a reference platform consuming a large portion of the Mu code can successfully build. The documentation produced for this tag contains any changes required to get the reference platform building. It includes a list of changes outside the Mu project that are recommended for any consuming platform. * _RefBoot This tag is placed on the commit where a reference platform consuming a large portion of the Mu code can successfully boot. The documentation produced for this tag contains any changes required to get the reference platform booting. It includes a list of changes outside the Mu project that are recommended for any consuming platform. In each of these cases, the * will be replaced with a corresponding branch name. For example, the tags associated with release / 201808 will be prefixed with 1808 (e.g. 1808 _Rebase , 1808 _RC1 , etc.). Active Development Phase \u00b6 During the active development phase, the release branch is open for comment and contribution both internally and publicly. All work contributed by the Project Mu team will be publicly available after an internal PR review. This commits will automatically be mirrored to the public repos. Similarly, all completed public PRs are mirrored in internal review repos (with preference being given to the public PR in event of a conflict). While this means that there will be times where Project Mu team will make contributions without going through a full public PR review, all code is open to comment and contribution, up to and including a full revert of the internal Mu team contribution. Public Contribution/Commentary \u00b6 For information on the contribution policies and steps, see the How to Contribute document. Upstream Cherry-Picks \u00b6 In the event that a critical change is made in the TianoCore upstream during the Active Development phase, the Project Mu team (with any suggestions or comment from downstream contributors) will evaluate the change for a mid-release cherry pick. If warranted, the commit(s) will be cherry-picked directly from TianoCore and prefixed with a \"CHERRY-PICK\" tag in the commit message so they can be cleaned up in the next rebase. Stabilization Phase \u00b6 When warranted, active development on the active release /* branch will be halted so that it may enter a period of rigorous testing and stabilization. Upon entering the Stabilization phase, the branch will be tagged with a * _RC1 tag and only bug fixes will be accepted from then on. Any defects or regressions found during stabilization will be fixed and documented. Once confidence is built in the stability of the code, the branch will be tagged as * _Stable and it will enter LTS. It is Project Mu's goal that this cadence be aligned with the TianoCore release cadence, with the previous branch stabilizing at the same time a new TianoCore release is available. In this way, development can seamlessly move to the next release /* branch without lapse in availability. Note It is possible that the * _RC1 tag be applied to the same commit as * _Stable if there are no defects found in the branch. (Because that happens all the time.) It is also possible that multiple * _RCn tags may be useful to distinguish between milestones of a particularly protracted Stabilization phase. Transition Branches \u00b6 In the event that it becomes necessary to stabilize a release /* branch prior to the availability of a suitable TianoCore commit for rebasing, all active development will move to a dev /* branch that will branch from the previous * _RC1 tag. If bugs are discovered in the Stabilization phase for the release /* branch, they will also be fixed in the dev /* branch and all changes made in the dev /* branch will be rebased as part of the next release /* branch when it is ready. Long-Term Support (LTS) \u00b6 It is Project Mu's goal that all release /* branches continue to be maintained with active bug fixes -- as necessary -- for at least two full releases after the branch becomes stable. The Project Mu team will serve as the primary deciding body for whether a bug fix to the current release /* branch merits porting back to the prior two branches, but community input or suggestions are always welcome. All release branches that make it to the Stabilization phase will be hosted and kept in the repository in perpetuity. If any change was required to this policy (perhaps for server considerations), the branches will remain archived for posterity and should be available by request. Lifetime of a Single Integration \u00b6 TBD","title":"Release Process"},{"location":"How/release_process/#overview","text":"Contents and Process Under Active Development The basics of this process are identical to those followed by the Project Mu firmware integration and release process internal to Microsoft, but the formal documentation, branch naming, and tagging process is a work in progress. While this is how we expect things to work, there may be changes within the the first few releases driven by feedback within the team and any external consumers/contributors. In the interest of maintaining a close, well-defined relationship with the upstream project, TianoCore, the active release branch of Project Mu is periodically deprecated and all Mu-related changes are rebased onto a selected commit of TianoCore. This keeps Project Mu up to date with TianoCore while highlighting all Project Mu differences in the most recent commits and encouraging the reverse integration of all changes/fixes back into TianoCore In general, the life-cycle of active code follows the following path: All active work in Project Mu is performed on a release /* branch, named sequentially according to the date of TianoCore commit that it's based on (e.g. release / 201808 is based on the edk2 - stable201808 branch in TianoCore). Work proceeds on that branch until a new TianoCore integration is targeted, at which point a new branch is created and all existing changes are rebased onto the new branch and the new branch is used for all active development going forward. At this point, the previous branch enters a stabilization period where further tests are performed and only bug fixes are allowed to be committed. After stabilization, the branch is labeled as stable and will only receive critical bug fixes either directly to the branch or backported from a more recent release. release /* branches will be maintained in LTS (Long-Term Support) for at least the next two releases. The below diagram illustrates the life-cycle of a single branch and indicates the critical points in its lifetime. These critical points will be applied as tags for reference and documentation. The tags are given a name relative to the target branch and consist of: Upstream base, Rebase complete, Rebase builds, Rebase boots, RCn, and Stable. These tags are discussed in more detail below. Important Due to the impacts of the rebase process on the history of Mu release branches, any downstream consumers will have to follow a similar integration process when upgrading to a new release. Any custom changes made within the Project Mu repos will have to be rebased from one release to the next. This is why we strongly discourage forking Project Mu for direct modification (ie. consumption, not contribution). Instead, leverage the distributed repo management system and override management system to integrate proprietary code/modules.","title":"Overview"},{"location":"How/release_process/#current-branch-status","text":"While the earliest release branches may not be included in this process, starting with release / 201903 and going forwards the status of each branch will be recorded in the README.rst file at the root of the branch. In general, the README found in Basecore will contain information that is common to all of the Mu submodules, but each submodule will also have its own README for each release branch that contains notes specific to the development that occurs in that submodule during a release cycle. The README will also contain a summary of the branch status at a given time. For example, here is a sample status for Basecore release / 201903 as of the time of this writing: Current Phase: Development Entered Current Phase: 2019/03/25 Planned Exit Date: May 2019","title":"Current Branch Status"},{"location":"How/release_process/#upstream-integration-phase","text":"At this time, we are targeting upstream integrations for roughly once a quarter, attempting to align 1:1 with the TianoCore stable release cadence. Prior to an integration, the status dashboard (not yet created) will be updated with the target date of completion and the target TianoCore commit and/or release. For example, a plan was made to transition off of release / 20180529 when TianoCore announced the edk2 - stable201808 release. Once a commit is selected, a set of rebase commits will be chosen from the active (previous) release /* branch. Ideally, these commits would include everything from the previous rebase through the most recent * _RC tag. For example, when moving from the release / 201808 branch, the commits will be selected from 1808 _Upstream (not inclusive) tag to 1808 _RC1 . After selection, this list of commits will be evaluated to determine whether any changes are no longer needed in the Mu history. The most likely causes of this action are: A change was submitted to TianoCore and has been accepted since the last rebase. Therefore, the change is no longer needed in Mu history. A change was reverted or modified more recently in Mu history, and the history of this change was squashed to maintain simplicity when comparing with upstream (TianoCore). Once all evaluation is completed, the rebase will be performed in the new release /* branch. This branch will then be built for a reference platform (to be selected by internal team) and booted, at which point it will be considered the active development branch.","title":"Upstream Integration Phase"},{"location":"How/release_process/#integration-milestone-tags","text":"During integration, multiple tags are applied to the branch to serve as milestones. They also serve as reference point for changelog documentation that is produced during the integration process. These tags are described below: * _Upstream This tag is placed on the exact TianoCore commit that a given release branch started from. This is used as a reference point between branches and relative to the rebase operation. The documentation produced for this tag contains the differences in TianoCore between this branch and the previous branch. For branches that originated from TianoCore releases, this changelog should be identical to the TianoCore changelog. * _Rebase This tag is placed on the commit at the branch HEAD once the rebase is completed. The only changes to the commits from the last branch should be merge conflict resolutions and any history simplification as described above. The documentation produced for this tag contains a record of these resolutions and simplifications. * _RefBuild This tag is placed on the commit where a reference platform consuming a large portion of the Mu code can successfully build. The documentation produced for this tag contains any changes required to get the reference platform building. It includes a list of changes outside the Mu project that are recommended for any consuming platform. * _RefBoot This tag is placed on the commit where a reference platform consuming a large portion of the Mu code can successfully boot. The documentation produced for this tag contains any changes required to get the reference platform booting. It includes a list of changes outside the Mu project that are recommended for any consuming platform. In each of these cases, the * will be replaced with a corresponding branch name. For example, the tags associated with release / 201808 will be prefixed with 1808 (e.g. 1808 _Rebase , 1808 _RC1 , etc.).","title":"Integration Milestone Tags"},{"location":"How/release_process/#active-development-phase","text":"During the active development phase, the release branch is open for comment and contribution both internally and publicly. All work contributed by the Project Mu team will be publicly available after an internal PR review. This commits will automatically be mirrored to the public repos. Similarly, all completed public PRs are mirrored in internal review repos (with preference being given to the public PR in event of a conflict). While this means that there will be times where Project Mu team will make contributions without going through a full public PR review, all code is open to comment and contribution, up to and including a full revert of the internal Mu team contribution.","title":"Active Development Phase"},{"location":"How/release_process/#public-contributioncommentary","text":"For information on the contribution policies and steps, see the How to Contribute document.","title":"Public Contribution/Commentary"},{"location":"How/release_process/#upstream-cherry-picks","text":"In the event that a critical change is made in the TianoCore upstream during the Active Development phase, the Project Mu team (with any suggestions or comment from downstream contributors) will evaluate the change for a mid-release cherry pick. If warranted, the commit(s) will be cherry-picked directly from TianoCore and prefixed with a \"CHERRY-PICK\" tag in the commit message so they can be cleaned up in the next rebase.","title":"Upstream Cherry-Picks"},{"location":"How/release_process/#stabilization-phase","text":"When warranted, active development on the active release /* branch will be halted so that it may enter a period of rigorous testing and stabilization. Upon entering the Stabilization phase, the branch will be tagged with a * _RC1 tag and only bug fixes will be accepted from then on. Any defects or regressions found during stabilization will be fixed and documented. Once confidence is built in the stability of the code, the branch will be tagged as * _Stable and it will enter LTS. It is Project Mu's goal that this cadence be aligned with the TianoCore release cadence, with the previous branch stabilizing at the same time a new TianoCore release is available. In this way, development can seamlessly move to the next release /* branch without lapse in availability. Note It is possible that the * _RC1 tag be applied to the same commit as * _Stable if there are no defects found in the branch. (Because that happens all the time.) It is also possible that multiple * _RCn tags may be useful to distinguish between milestones of a particularly protracted Stabilization phase.","title":"Stabilization Phase"},{"location":"How/release_process/#transition-branches","text":"In the event that it becomes necessary to stabilize a release /* branch prior to the availability of a suitable TianoCore commit for rebasing, all active development will move to a dev /* branch that will branch from the previous * _RC1 tag. If bugs are discovered in the Stabilization phase for the release /* branch, they will also be fixed in the dev /* branch and all changes made in the dev /* branch will be rebased as part of the next release /* branch when it is ready.","title":"Transition Branches"},{"location":"How/release_process/#long-term-support-lts","text":"It is Project Mu's goal that all release /* branches continue to be maintained with active bug fixes -- as necessary -- for at least two full releases after the branch becomes stable. The Project Mu team will serve as the primary deciding body for whether a bug fix to the current release /* branch merits porting back to the prior two branches, but community input or suggestions are always welcome. All release branches that make it to the Stabilization phase will be hosted and kept in the repository in perpetuity. If any change was required to this policy (perhaps for server considerations), the branches will remain archived for posterity and should be available by request.","title":"Long-Term Support (LTS)"},{"location":"How/release_process/#lifetime-of-a-single-integration","text":"TBD","title":"Lifetime of a Single Integration"},{"location":"How/using_project_mu/","text":"How to setup a new Repo for a Platform that will use Project MU? \u00b6 This document will describe the base guidelines for setting up a Project MU repo. You will need: 1) Git 2) Python 3.7 3) A text editor 4) Look at layout to understand our recommended repository layout. You can also look at ms-iot iMX8 for a real platform implementation. 0) Nomenclature \u00b6 I will use the term workspace root to reference the base folder for your code tree. Ordinarily, we use the Platform Repository as the outer-most layer. This means that the outermost git repository is where we store Platform specific files and libraries. In this case, our Platform Repo is also our workspace root . If you choose to have a different repository layout, it will be important to note what your workspace root is, as it should still be the base folder of your code tree. Submodules are full git repos on their own. What we do with these repos is add them as sub-repos to the workspace root . Git will create a .gitmodules file that contains links to the repo and default branches. There are git submodule commands that you can use to work with your submodules, such as: git submodule add <url> <path> # url to submodule, path to submodule installation git submodule update --init --recursive # Recursively initializes and updates all submodules. git submodule foreach git status # git submodule foreach can be used to run a command in each submodule. git status is just an example. For more information available here . 1) Create Git Repo \u00b6 Make new directory. mkdir NewPlatformRepo cd NewPlatformRepo git init This will serve as our Platform Repository as well as our Workspace Root. For more information on creating a Git repo, here are command line instructions and here are web instructions . 2) Add pertinent submodules \u00b6 Project MU is separated into submodules. For each submodule that you need for your project, run the \"git submodule add\" command to add it to your base Repository. The path after the URL is the path we typically use to group the submodules. You can change it if you'd like, just remember your environment will diverge from the one in these instructions. MU_BASECORE \u00b6 This is the core section of TianoCore. Contains the guts of UEFI, forked from TianoCore, as well as the BaseTools needed to build. You will need this to continue. git submodule add https : // github . com / Microsoft / mu_basecore . git MU_BASECORE MU_PLUS \u00b6 Additional, optional libraries and tools we've added to make MU great! git submodule add https : // github . com / Microsoft / mu_plus . git Common / MU MU_TIANO_PLUS \u00b6 Additional, optional libraries and tools forked from TianoCore. git submodule add https : // github . com / Microsoft / mu_tiano_plus . git Common / TIANO MU_OEM_SAMPLE \u00b6 This module is a sample implementation of a FrontPage and several BDS support libraries. This module is intended to be forked and customized. git submodule add https : // github . com / Microsoft / mu_oem_sample . git Common / MU_OEM_SAMPLE MU_SILICON_ARM_TIANO \u00b6 Silicon code from TianoCore has been broken out into individual submodules. This is the ARM specific submodule. git submodule add https : // github . com / Microsoft / mu_silicon_arm_tiano . git Silicon / ARM / TIANO MU_SILICON_INTEL_TIANO \u00b6 Silicon code from TianoCore has been broken out into individual submodules. This is the Intel specific submodule. git submodule add https : // github . com / Microsoft / mu_silicon_intel_tiano . git Silicon / INTEL / TIANO You can run git submodule --update --init to make sure all the submodules are set up. 3) Adding your platform contents \u00b6 New_Platform_Repo / \u251c\u2500\u2500 Common / \u2502 \u2514\u2500\u2500 ... # MU_PLUS , MU_OEM_SAMPLE , MU_TIANO_PLUS are generally created by the \" git submodule ... \" commands shown above \u251c\u2500\u2500 MU_BASECORE / \u251c\u2500\u2500 PlatformGroup / \u2502 \u2514\u2500\u2500 PlatformName / \u2502 \u2514\u2500\u2500 PlatformBuild . py # Python script to provide information to the build process . \u2502 \u2514\u2500\u2500 Platform . dsc # List of UEFI libraries and drivers to compile , as well as platform settings . \u2502 \u2514\u2500\u2500 Platform . fdf # List of UEFI Drivers to put into Firmware Volumes . \u251c\u2500\u2500 Silicon / \u2502 \u2514\u2500\u2500 SiProvider / # You may want to create a separate git repo for Silicon code to enable development with partners . \u2502 \u2514\u2500\u2500 REF_CODE / # Enablement code for your architecture \u251c\u2500\u2500 . gitattributes \u251c\u2500\u2500 . gitignore \u2514\u2500\u2500 . gitmodules You will need to create PlatformBuild.py, Platform.dsc, and Platform.fdf. These files will go inside the platform folder, which will be New_Platform_Repo / PlatformGroup / PlatformName . The ms-iot iMX8 repo can help you get started as a layout reference and can demonstrate the PlatformBuild file. More information about PlatformBuild can be found here . 4) Build instructions \u00b6 There are documents explaining our build system. This will be updated as things change.","title":"Using"},{"location":"How/using_project_mu/#how-to-setup-a-new-repo-for-a-platform-that-will-use-project-mu","text":"This document will describe the base guidelines for setting up a Project MU repo. You will need: 1) Git 2) Python 3.7 3) A text editor 4) Look at layout to understand our recommended repository layout. You can also look at ms-iot iMX8 for a real platform implementation.","title":"How to setup a new Repo for a Platform that will use Project MU?"},{"location":"How/using_project_mu/#0-nomenclature","text":"I will use the term workspace root to reference the base folder for your code tree. Ordinarily, we use the Platform Repository as the outer-most layer. This means that the outermost git repository is where we store Platform specific files and libraries. In this case, our Platform Repo is also our workspace root . If you choose to have a different repository layout, it will be important to note what your workspace root is, as it should still be the base folder of your code tree. Submodules are full git repos on their own. What we do with these repos is add them as sub-repos to the workspace root . Git will create a .gitmodules file that contains links to the repo and default branches. There are git submodule commands that you can use to work with your submodules, such as: git submodule add <url> <path> # url to submodule, path to submodule installation git submodule update --init --recursive # Recursively initializes and updates all submodules. git submodule foreach git status # git submodule foreach can be used to run a command in each submodule. git status is just an example. For more information available here .","title":"0) Nomenclature"},{"location":"How/using_project_mu/#1-create-git-repo","text":"Make new directory. mkdir NewPlatformRepo cd NewPlatformRepo git init This will serve as our Platform Repository as well as our Workspace Root. For more information on creating a Git repo, here are command line instructions and here are web instructions .","title":"1) Create Git Repo"},{"location":"How/using_project_mu/#2-add-pertinent-submodules","text":"Project MU is separated into submodules. For each submodule that you need for your project, run the \"git submodule add\" command to add it to your base Repository. The path after the URL is the path we typically use to group the submodules. You can change it if you'd like, just remember your environment will diverge from the one in these instructions.","title":"2) Add pertinent submodules"},{"location":"How/using_project_mu/#mu_basecore","text":"This is the core section of TianoCore. Contains the guts of UEFI, forked from TianoCore, as well as the BaseTools needed to build. You will need this to continue. git submodule add https : // github . com / Microsoft / mu_basecore . git MU_BASECORE","title":"MU_BASECORE"},{"location":"How/using_project_mu/#mu_plus","text":"Additional, optional libraries and tools we've added to make MU great! git submodule add https : // github . com / Microsoft / mu_plus . git Common / MU","title":"MU_PLUS"},{"location":"How/using_project_mu/#mu_tiano_plus","text":"Additional, optional libraries and tools forked from TianoCore. git submodule add https : // github . com / Microsoft / mu_tiano_plus . git Common / TIANO","title":"MU_TIANO_PLUS"},{"location":"How/using_project_mu/#mu_oem_sample","text":"This module is a sample implementation of a FrontPage and several BDS support libraries. This module is intended to be forked and customized. git submodule add https : // github . com / Microsoft / mu_oem_sample . git Common / MU_OEM_SAMPLE","title":"MU_OEM_SAMPLE"},{"location":"How/using_project_mu/#mu_silicon_arm_tiano","text":"Silicon code from TianoCore has been broken out into individual submodules. This is the ARM specific submodule. git submodule add https : // github . com / Microsoft / mu_silicon_arm_tiano . git Silicon / ARM / TIANO","title":"MU_SILICON_ARM_TIANO"},{"location":"How/using_project_mu/#mu_silicon_intel_tiano","text":"Silicon code from TianoCore has been broken out into individual submodules. This is the Intel specific submodule. git submodule add https : // github . com / Microsoft / mu_silicon_intel_tiano . git Silicon / INTEL / TIANO You can run git submodule --update --init to make sure all the submodules are set up.","title":"MU_SILICON_INTEL_TIANO"},{"location":"How/using_project_mu/#3-adding-your-platform-contents","text":"New_Platform_Repo / \u251c\u2500\u2500 Common / \u2502 \u2514\u2500\u2500 ... # MU_PLUS , MU_OEM_SAMPLE , MU_TIANO_PLUS are generally created by the \" git submodule ... \" commands shown above \u251c\u2500\u2500 MU_BASECORE / \u251c\u2500\u2500 PlatformGroup / \u2502 \u2514\u2500\u2500 PlatformName / \u2502 \u2514\u2500\u2500 PlatformBuild . py # Python script to provide information to the build process . \u2502 \u2514\u2500\u2500 Platform . dsc # List of UEFI libraries and drivers to compile , as well as platform settings . \u2502 \u2514\u2500\u2500 Platform . fdf # List of UEFI Drivers to put into Firmware Volumes . \u251c\u2500\u2500 Silicon / \u2502 \u2514\u2500\u2500 SiProvider / # You may want to create a separate git repo for Silicon code to enable development with partners . \u2502 \u2514\u2500\u2500 REF_CODE / # Enablement code for your architecture \u251c\u2500\u2500 . gitattributes \u251c\u2500\u2500 . gitignore \u2514\u2500\u2500 . gitmodules You will need to create PlatformBuild.py, Platform.dsc, and Platform.fdf. These files will go inside the platform folder, which will be New_Platform_Repo / PlatformGroup / PlatformName . The ms-iot iMX8 repo can help you get started as a layout reference and can demonstrate the PlatformBuild file. More information about PlatformBuild can be found here .","title":"3) Adding your platform contents"},{"location":"How/using_project_mu/#4-build-instructions","text":"There are documents explaining our build system. This will be updated as things change.","title":"4) Build instructions"},{"location":"WhatAndWhy/features/","text":"Features \u00b6 Summary \u00b6 Project Mu features will generally be found in a \"MU\" sub-module, for example, \"Common/MU\" or \"Silicon/Intel/MU\". What major features does Project Mu bring to the table above/beyond EDK2? Feature List \u00b6 Pluggable, cross-device, performance-optimized BDS Device Firmware Configuration Interface (DFCI) - enables practical MDM management PBKDF2-based BIOS password example Support for EKU-based trust anchors during signature validation Microsoft unit test framework Audit, function, & performance tests for platform features Scalable Python build environment Build plug in: override tracking tool Build plug in: flash descriptor analysis Binary package management via NuGet Capsule signing via signtool.exe Up-to-date Visual Studio compiler support Base64 encode for binary objects XML Support Package Features Coming Soon \u00b6 Modern BIOS menu example (Surface inspired) On screen keyboard (OSK) with mouse, touch support Graphical end-to-end boot performance analysis library and tool Infineon TPM firmware update via Capsule On screen notifications: color bars to inform users that a device is not in a production configuration Features integrated into Tiano \u00b6 Safe Integer library Heap Guard ESRT DXE driver Scalable device FMP framework Progress bar for Capsule Updates TCG FV pre hashing optimization NVME shutdown","title":"Features"},{"location":"WhatAndWhy/features/#features","text":"","title":"Features"},{"location":"WhatAndWhy/features/#summary","text":"Project Mu features will generally be found in a \"MU\" sub-module, for example, \"Common/MU\" or \"Silicon/Intel/MU\". What major features does Project Mu bring to the table above/beyond EDK2?","title":"Summary"},{"location":"WhatAndWhy/features/#feature-list","text":"Pluggable, cross-device, performance-optimized BDS Device Firmware Configuration Interface (DFCI) - enables practical MDM management PBKDF2-based BIOS password example Support for EKU-based trust anchors during signature validation Microsoft unit test framework Audit, function, & performance tests for platform features Scalable Python build environment Build plug in: override tracking tool Build plug in: flash descriptor analysis Binary package management via NuGet Capsule signing via signtool.exe Up-to-date Visual Studio compiler support Base64 encode for binary objects XML Support Package","title":"Feature List"},{"location":"WhatAndWhy/features/#features-coming-soon","text":"Modern BIOS menu example (Surface inspired) On screen keyboard (OSK) with mouse, touch support Graphical end-to-end boot performance analysis library and tool Infineon TPM firmware update via Capsule On screen notifications: color bars to inform users that a device is not in a production configuration","title":"Features Coming Soon"},{"location":"WhatAndWhy/features/#features-integrated-into-tiano","text":"Safe Integer library Heap Guard ESRT DXE driver Scalable device FMP framework Progress bar for Capsule Updates TCG FV pre hashing optimization NVME shutdown","title":"Features integrated into Tiano"},{"location":"WhatAndWhy/layout/","text":"Dependencies and Layout \u00b6 Conceptual Layers \u00b6 A modern, full-featured, product-ready UEFI firmware codebase combines code from a multitude of sources: TianoCore EDK2 UEFI standard-based code Value-add code from TianoCore Silicon vendor hardware initialization code Silicon vendor value-add code Independent BIOS Vendor code ODM/OEM customization code OS firmware support code Legacy BIOS compatibility code Board-specific code etc. Some of the above components come from closed-source projects (silicon vendors, IBVs, OEMs), others are open source. Each component is supported at its own schedule with new features and bug fixes, creating a problem of stale code if not synced up regularly. Compound the version and source problem with the sheer size: a common UEFI codebase is typically well above 1 million LOC and only goes up from there. What is a dependency \u00b6 To understand the layering you must first understand the terminology. There are two types of code assets. A definition of something. Generally, this is defined in an accessible header file. This is the API provided by some asset. This API can be \"depended\" upon to provide some capability. An implementation of something. Example of a dependency: DxeCore in the Basecore layer includes a TimerLib interface. TimerLib interface is defined in the same Basecore layer as DxeCore, so in this case a Basecore module is depending on a Basecore interface. This is allowed. Another example: Silicon-layer module implements a TimerLib interface defined in Basecore. Here, a Silicon layer module depends on a Basecore interface. This is allowed. Architecture \u00b6 Project Mu is an attempt to create a rigid layering scheme that defines the hierarchy of dependencies. Architectural goal kept in mind when designing this layering scheme is a controlled, limited scope, and allowed dependencies for each module within a given layer. It is important to know, when implementing a module, what the module is allowed to depend on. When creating an interface, it is important to identify the correct layer for it such that all the consuming modules are located in the layers below. Motivation and goals of the layering scheme: Easy component integration Code reuse Only carry relevant code Dependency Block Diagram \u00b6 File Layout \u00b6 To best preserve and delineate these concepts of componentization and unidirectional dependency, we have chosen to lay out our repository files in a structure that reinforces the same mentality. The underlying logic of this layout is to clearly distinguish each layer from the rest. As such, the Basecore -- which is considered foundational -- is broken out on its own, followed by the Common repos, followed by the Silicon, followed by the Platform. As mentioned elsewhere, Project Mu makes liberal use of multiple repositories due to the mixture of requirements in the firmware ecosystem. Some repos are split for technical reasons, some for organizational, and some for legal. One of the goals of Project Mu is to make this seemingly complicated layout easier to work with. Min Platform Example \u00b6 A simple tree might look like this... project_mu / \u251c\u2500\u2500 Build / \u251c\u2500\u2500 Common / \u2502 \u2514\u2500\u2500 ... # Common code optional , but probably not required \u251c\u2500\u2500 Conf / \u251c\u2500\u2500 MU_BASECORE / \u251c\u2500\u2500 Platform / \u2502 \u2514\u2500\u2500 Sample / \u2502 \u2514\u2500\u2500 MyMinPlatform # Platform - specific build files and code \u251c\u2500\u2500 Silicon / \u2502 \u2514\u2500\u2500 SiProvider / \u2502 \u2514\u2500\u2500 REF_CODE / # Enablement code for your architecture \u251c\u2500\u2500 . gitattributes \u251c\u2500\u2500 . gitignore \u2514\u2500\u2500 . gitmodules Note that this file structure is likely located in a Git repository, and every \"ALL CAPS\" directory in this example is a Git submodule/nested repository. Surface Laptop Example \u00b6 For a real-world example, this is a tree that could build the Surface Laptop product, including both open- and closed-source repositories: project_mu / \u251c\u2500\u2500 Build / \u251c\u2500\u2500 Common / \u2502 \u251c\u2500\u2500 MSCORE_INTERNAL / # Proprietary code and code not yet approved for public distribution \u2502 \u251c\u2500\u2500 MU / \u2502 \u251c\u2500\u2500 MU_TIANO / \u2502 \u2514\u2500\u2500 SURFACE / # Shared code to enable common features like FrontPage \u251c\u2500\u2500 Conf / \u251c\u2500\u2500 MU_BASECORE / \u251c\u2500\u2500 Platform / \u2502 \u251c\u2500\u2500 Surface / \u2502 \u2502 \u251c\u2500\u2500 SurfKbl / \u2502 \u2502 \u2502 \u2514\u2500\u2500 Laptop / # Surface Laptop - Specific Platform Code \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 Others / \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 Silicon / \u2502 \u251c\u2500\u2500 Intel / \u2502 \u2502 \u251c\u2500\u2500 KBL / # Intel KBL Reference Code \u2502 \u2502 \u251c\u2500\u2500 MU / # Project Mu Intel Common Code \u2502 \u2502 \u251c\u2500\u2500 MU_TIANO / # Project Mu Intel Code from TianoCore \u2502 \u2502 \u2514\u2500\u2500 SURF_KBL / # Surface Customizations / Overrides for KBL Ref Code \u2502 \u2514\u2500\u2500 SURFACE / # Shared code to enable common HW like ECs \u251c\u2500\u2500 . gitattributes \u251c\u2500\u2500 . gitignore \u2514\u2500\u2500 . gitmodules Once again, the \"ALL CAPS\" directories are submodules.","title":"Dependencies and Layout"},{"location":"WhatAndWhy/layout/#dependencies-and-layout","text":"","title":"Dependencies and Layout"},{"location":"WhatAndWhy/layout/#conceptual-layers","text":"A modern, full-featured, product-ready UEFI firmware codebase combines code from a multitude of sources: TianoCore EDK2 UEFI standard-based code Value-add code from TianoCore Silicon vendor hardware initialization code Silicon vendor value-add code Independent BIOS Vendor code ODM/OEM customization code OS firmware support code Legacy BIOS compatibility code Board-specific code etc. Some of the above components come from closed-source projects (silicon vendors, IBVs, OEMs), others are open source. Each component is supported at its own schedule with new features and bug fixes, creating a problem of stale code if not synced up regularly. Compound the version and source problem with the sheer size: a common UEFI codebase is typically well above 1 million LOC and only goes up from there.","title":"Conceptual Layers"},{"location":"WhatAndWhy/layout/#what-is-a-dependency","text":"To understand the layering you must first understand the terminology. There are two types of code assets. A definition of something. Generally, this is defined in an accessible header file. This is the API provided by some asset. This API can be \"depended\" upon to provide some capability. An implementation of something. Example of a dependency: DxeCore in the Basecore layer includes a TimerLib interface. TimerLib interface is defined in the same Basecore layer as DxeCore, so in this case a Basecore module is depending on a Basecore interface. This is allowed. Another example: Silicon-layer module implements a TimerLib interface defined in Basecore. Here, a Silicon layer module depends on a Basecore interface. This is allowed.","title":"What is a dependency"},{"location":"WhatAndWhy/layout/#architecture","text":"Project Mu is an attempt to create a rigid layering scheme that defines the hierarchy of dependencies. Architectural goal kept in mind when designing this layering scheme is a controlled, limited scope, and allowed dependencies for each module within a given layer. It is important to know, when implementing a module, what the module is allowed to depend on. When creating an interface, it is important to identify the correct layer for it such that all the consuming modules are located in the layers below. Motivation and goals of the layering scheme: Easy component integration Code reuse Only carry relevant code","title":"Architecture"},{"location":"WhatAndWhy/layout/#dependency-block-diagram","text":"","title":"Dependency Block Diagram"},{"location":"WhatAndWhy/layout/#file-layout","text":"To best preserve and delineate these concepts of componentization and unidirectional dependency, we have chosen to lay out our repository files in a structure that reinforces the same mentality. The underlying logic of this layout is to clearly distinguish each layer from the rest. As such, the Basecore -- which is considered foundational -- is broken out on its own, followed by the Common repos, followed by the Silicon, followed by the Platform. As mentioned elsewhere, Project Mu makes liberal use of multiple repositories due to the mixture of requirements in the firmware ecosystem. Some repos are split for technical reasons, some for organizational, and some for legal. One of the goals of Project Mu is to make this seemingly complicated layout easier to work with.","title":"File Layout"},{"location":"WhatAndWhy/layout/#min-platform-example","text":"A simple tree might look like this... project_mu / \u251c\u2500\u2500 Build / \u251c\u2500\u2500 Common / \u2502 \u2514\u2500\u2500 ... # Common code optional , but probably not required \u251c\u2500\u2500 Conf / \u251c\u2500\u2500 MU_BASECORE / \u251c\u2500\u2500 Platform / \u2502 \u2514\u2500\u2500 Sample / \u2502 \u2514\u2500\u2500 MyMinPlatform # Platform - specific build files and code \u251c\u2500\u2500 Silicon / \u2502 \u2514\u2500\u2500 SiProvider / \u2502 \u2514\u2500\u2500 REF_CODE / # Enablement code for your architecture \u251c\u2500\u2500 . gitattributes \u251c\u2500\u2500 . gitignore \u2514\u2500\u2500 . gitmodules Note that this file structure is likely located in a Git repository, and every \"ALL CAPS\" directory in this example is a Git submodule/nested repository.","title":"Min Platform Example"},{"location":"WhatAndWhy/layout/#surface-laptop-example","text":"For a real-world example, this is a tree that could build the Surface Laptop product, including both open- and closed-source repositories: project_mu / \u251c\u2500\u2500 Build / \u251c\u2500\u2500 Common / \u2502 \u251c\u2500\u2500 MSCORE_INTERNAL / # Proprietary code and code not yet approved for public distribution \u2502 \u251c\u2500\u2500 MU / \u2502 \u251c\u2500\u2500 MU_TIANO / \u2502 \u2514\u2500\u2500 SURFACE / # Shared code to enable common features like FrontPage \u251c\u2500\u2500 Conf / \u251c\u2500\u2500 MU_BASECORE / \u251c\u2500\u2500 Platform / \u2502 \u251c\u2500\u2500 Surface / \u2502 \u2502 \u251c\u2500\u2500 SurfKbl / \u2502 \u2502 \u2502 \u2514\u2500\u2500 Laptop / # Surface Laptop - Specific Platform Code \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 Others / \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 Silicon / \u2502 \u251c\u2500\u2500 Intel / \u2502 \u2502 \u251c\u2500\u2500 KBL / # Intel KBL Reference Code \u2502 \u2502 \u251c\u2500\u2500 MU / # Project Mu Intel Common Code \u2502 \u2502 \u251c\u2500\u2500 MU_TIANO / # Project Mu Intel Code from TianoCore \u2502 \u2502 \u2514\u2500\u2500 SURF_KBL / # Surface Customizations / Overrides for KBL Ref Code \u2502 \u2514\u2500\u2500 SURFACE / # Shared code to enable common HW like ECs \u251c\u2500\u2500 . gitattributes \u251c\u2500\u2500 . gitignore \u2514\u2500\u2500 . gitmodules Once again, the \"ALL CAPS\" directories are submodules.","title":"Surface Laptop Example"},{"location":"WhatAndWhy/overview/","text":"Overview \u00b6 Project Organization \u00b6 This documentation is hosted in the main repository for Project Mu, which is used as a central collection point for community interaction and documentation. The build system and firmware code for the project is hosted in a number of other repositories, grouped/divided by function, partner, license, and dependencies. Several of these repositories are brought together by the build system to create a FW project, but we'll get into those details later. ;) For now, an overview of the repositories and what code you'll find there... Mu Basecore \u00b6 This repository is considered foundational and fundamental to Project Mu. The guiding philosophy is that this code should be one or more of the following: Part of the build system Common to any silicon architecture Part of the \"API layer\" that contains protocol and library definitions including Industry Standards UEFI Specifications ACPI Specifications Part of the \"PI\" layer that contains driver dispatch logic, event/signaling logic, or memory management logic This can also include central technologies like variable services Mu Common Plus \u00b6 The packages found in this repository are contributed entirely by Project Mu. They should be common to all silicon architectures and only depend on Mu Basecore. These packages provide features and functionality that are entirely optional, but may be recommended for PC platform FW. Mu Tiano Plus \u00b6 This repository contains only modules that were originally sourced from TianoCore. They are not essential for any particular platform, but are likely useful to many platforms. The versions contained in this repo are modified and/or improved to work with the rest of Project Mu. Repo Philosophy \u00b6 Project Mu makes liberal use of multiple repositories due to the mixture of requirements in the UEFI ecosystem. Some repos are split for technical reasons, some for organizational, and some for legal. Examples of this are: A downstream contributor wants to add a generic feature with a silicon-specific implementation. This feature would be leveraged by Common code. If all code were in one repository, no barriers would be in place to prevent the contributor from directly calling from Common code into the Silicon implementation. By forcing the API/interface to be published in a separate repository, we can ensure that the unidirectional dependency relationship is maintained. Module A and Module B both provide optional functionality. However, Module A is far more likely to be consume by a wide audience than Module B. To achieve \"Less is More\", Module A may be placed in a different repos to enable downstream consumers to carry as little \"unused\" code as possible, since it's likely they would not need Module B in their code tree. A downstream consumer is producing a product in conjunction with a vendor/partner. While most of the enabling code for the vendor component is open-source, a portion of it is only released under NDA. By having multiple repositories comprise a single workspace, the downstream consumer is able to maximize their open-source consumption (which minimizes forking) while maintaining the legal requirements of closed-source/proprietary partitioning.","title":"Overview"},{"location":"WhatAndWhy/overview/#overview","text":"","title":"Overview"},{"location":"WhatAndWhy/overview/#project-organization","text":"This documentation is hosted in the main repository for Project Mu, which is used as a central collection point for community interaction and documentation. The build system and firmware code for the project is hosted in a number of other repositories, grouped/divided by function, partner, license, and dependencies. Several of these repositories are brought together by the build system to create a FW project, but we'll get into those details later. ;) For now, an overview of the repositories and what code you'll find there...","title":"Project Organization"},{"location":"WhatAndWhy/overview/#mu-basecore","text":"This repository is considered foundational and fundamental to Project Mu. The guiding philosophy is that this code should be one or more of the following: Part of the build system Common to any silicon architecture Part of the \"API layer\" that contains protocol and library definitions including Industry Standards UEFI Specifications ACPI Specifications Part of the \"PI\" layer that contains driver dispatch logic, event/signaling logic, or memory management logic This can also include central technologies like variable services","title":"Mu Basecore"},{"location":"WhatAndWhy/overview/#mu-common-plus","text":"The packages found in this repository are contributed entirely by Project Mu. They should be common to all silicon architectures and only depend on Mu Basecore. These packages provide features and functionality that are entirely optional, but may be recommended for PC platform FW.","title":"Mu Common Plus"},{"location":"WhatAndWhy/overview/#mu-tiano-plus","text":"This repository contains only modules that were originally sourced from TianoCore. They are not essential for any particular platform, but are likely useful to many platforms. The versions contained in this repo are modified and/or improved to work with the rest of Project Mu.","title":"Mu Tiano Plus"},{"location":"WhatAndWhy/overview/#repo-philosophy","text":"Project Mu makes liberal use of multiple repositories due to the mixture of requirements in the UEFI ecosystem. Some repos are split for technical reasons, some for organizational, and some for legal. Examples of this are: A downstream contributor wants to add a generic feature with a silicon-specific implementation. This feature would be leveraged by Common code. If all code were in one repository, no barriers would be in place to prevent the contributor from directly calling from Common code into the Silicon implementation. By forcing the API/interface to be published in a separate repository, we can ensure that the unidirectional dependency relationship is maintained. Module A and Module B both provide optional functionality. However, Module A is far more likely to be consume by a wide audience than Module B. To achieve \"Less is More\", Module A may be placed in a different repos to enable downstream consumers to carry as little \"unused\" code as possible, since it's likely they would not need Module B in their code tree. A downstream consumer is producing a product in conjunction with a vendor/partner. While most of the enabling code for the vendor component is open-source, a portion of it is only released under NDA. By having multiple repositories comprise a single workspace, the downstream consumer is able to maximize their open-source consumption (which minimizes forking) while maintaining the legal requirements of closed-source/proprietary partitioning.","title":"Repo Philosophy"},{"location":"Where/external_resources/","text":"External Resources \u00b6 UEFI Industry Organization \u00b6 UEFI is the industry standards body that develops and distributes the UEFI, PI, and ACPI specifications. These specifications govern the firmware interfaces between OS, OEM/Device Manufacturer, and Silicon partner. This is a great site to download the industry specifications and if you are a member you can join working groups for future specifications. TianoCore Project \u00b6 Tianocore is an existing open source project. Their EDK2 repository is the basis for many/most UEFI implementations used on products today. It provides UEFI spec compliant code modules, supports industry standard hardware, and a multi-platform build environment. This is a great site to download specifications for the different file types and build process. It also has links to repositories that Project Mu tracks as \"upstreams\". MkDocs \u00b6 Great tool for creating documentation websites based on markdown. In fact it was used to generate this documentation. Markdown Help \u00b6 Quick link for common markdown support.","title":"External Resources"},{"location":"Where/external_resources/#external-resources","text":"","title":"External Resources"},{"location":"Where/external_resources/#uefi-industry-organization","text":"UEFI is the industry standards body that develops and distributes the UEFI, PI, and ACPI specifications. These specifications govern the firmware interfaces between OS, OEM/Device Manufacturer, and Silicon partner. This is a great site to download the industry specifications and if you are a member you can join working groups for future specifications.","title":"UEFI Industry Organization"},{"location":"Where/external_resources/#tianocore-project","text":"Tianocore is an existing open source project. Their EDK2 repository is the basis for many/most UEFI implementations used on products today. It provides UEFI spec compliant code modules, supports industry standard hardware, and a multi-platform build environment. This is a great site to download specifications for the different file types and build process. It also has links to repositories that Project Mu tracks as \"upstreams\".","title":"TianoCore Project"},{"location":"Where/external_resources/#mkdocs","text":"Great tool for creating documentation websites based on markdown. In fact it was used to generate this documentation.","title":"MkDocs"},{"location":"Where/external_resources/#markdown-help","text":"Quick link for common markdown support.","title":"Markdown Help"},{"location":"Where/project_resources/","text":"Project Resources \u00b6 Public Source Code Repositories \u00b6 Listed here: GitHub Project Mu Repo List Issue/Bug/Feature Tracking \u00b6 https://github.com/Microsoft/mu/issues Builds \u00b6 https://dev.azure.com/projectmu/mu/_build Docs \u00b6 https://microsoft.github.io/mu/ Collaborate \u00b6 Send an email request to join the discussion on our Teams channels. Help \u00b6 For one-off questions, feel free to open an Issue against the Mu repo with the \"question\" tag https://github.com/Microsoft/mu/issues For deeper discussion & faster communication, join our Microsoft Teams channels. To join send an email request .","title":"Project Resources"},{"location":"Where/project_resources/#project-resources","text":"","title":"Project Resources"},{"location":"Where/project_resources/#public-source-code-repositories","text":"Listed here: GitHub Project Mu Repo List","title":"Public Source Code Repositories"},{"location":"Where/project_resources/#issuebugfeature-tracking","text":"https://github.com/Microsoft/mu/issues","title":"Issue/Bug/Feature Tracking"},{"location":"Where/project_resources/#builds","text":"https://dev.azure.com/projectmu/mu/_build","title":"Builds"},{"location":"Where/project_resources/#docs","text":"https://microsoft.github.io/mu/","title":"Docs"},{"location":"Where/project_resources/#collaborate","text":"Send an email request to join the discussion on our Teams channels.","title":"Collaborate"},{"location":"Where/project_resources/#help","text":"For one-off questions, feel free to open an Issue against the Mu repo with the \"question\" tag https://github.com/Microsoft/mu/issues For deeper discussion & faster communication, join our Microsoft Teams channels. To join send an email request .","title":"Help"},{"location":"dyn/mu_pip_build/RepoDetails/","text":"Project Mu Pip Build \u00b6 Git Details Repository Url: https://github.com/Microsoft/mu_pip_build.git Branch: master Commit: 630920254fe10e41845c98efe0acaddb06fe5351 Commit Date: 2019-03-19 17:27:57 +0000 Provided with config file, mu_build fetches/clones dependencies then compiles every module in each package. This is the entrypoint into the CI / Pull Request build and test infrastructure. More Info \u00b6 Please see the Project Mu docs ( https://github.com/Microsoft/mu ) for more information. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Issues \u00b6 Please open any issues in the Project Mu GitHub tracker. More Details Contributing Code or Docs \u00b6 Please follow the general Project Mu Pull Request process. More Details Additionally make sure all testing described in the \"Development\" section passes. Using \u00b6 Usage Details Development \u00b6 Development Details Publish \u00b6 Publish Details Copyright & License \u00b6 Copyright \u00a9 2016-2018, Microsoft Corporation All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Repo Details"},{"location":"dyn/mu_pip_build/RepoDetails/#project-mu-pip-build","text":"Git Details Repository Url: https://github.com/Microsoft/mu_pip_build.git Branch: master Commit: 630920254fe10e41845c98efe0acaddb06fe5351 Commit Date: 2019-03-19 17:27:57 +0000 Provided with config file, mu_build fetches/clones dependencies then compiles every module in each package. This is the entrypoint into the CI / Pull Request build and test infrastructure.","title":"Project Mu Pip Build"},{"location":"dyn/mu_pip_build/RepoDetails/#more-info","text":"Please see the Project Mu docs ( https://github.com/Microsoft/mu ) for more information. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"More Info"},{"location":"dyn/mu_pip_build/RepoDetails/#issues","text":"Please open any issues in the Project Mu GitHub tracker. More Details","title":"Issues"},{"location":"dyn/mu_pip_build/RepoDetails/#contributing-code-or-docs","text":"Please follow the general Project Mu Pull Request process. More Details Additionally make sure all testing described in the \"Development\" section passes.","title":"Contributing Code or Docs"},{"location":"dyn/mu_pip_build/RepoDetails/#using","text":"Usage Details","title":"Using"},{"location":"dyn/mu_pip_build/RepoDetails/#development","text":"Development Details","title":"Development"},{"location":"dyn/mu_pip_build/RepoDetails/#publish","text":"Publish Details","title":"Publish"},{"location":"dyn/mu_pip_build/RepoDetails/#copyright-license","text":"Copyright \u00a9 2016-2018, Microsoft Corporation All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Copyright &amp; License"},{"location":"dyn/mu_pip_build/developing/","text":"Developing Project Mu Pip Build \u00b6 Pre-Requisites \u00b6 Get the code git clone https : // github . com / Microsoft / mu_pip_build . git Install development dependencies pip install --upgrade -r requirements.txt Uninstall any copy of mu_build pip uninstall mu_build Install from local source (run command from root of repo) pip install - e . Testing \u00b6 Run a Basic Syntax/Lint Check (using flake8) and resolve any issues flake8 MuBuild Info Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run pytest with coverage data collected pytest - v --junitxml=test.junit.xml --html=pytest_MuBuild_report.html --self-contained-html --cov=MuBuild --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_MuBuild_report.html cov_html/index.html","title":"developing"},{"location":"dyn/mu_pip_build/developing/#developing-project-mu-pip-build","text":"","title":"Developing Project Mu Pip Build"},{"location":"dyn/mu_pip_build/developing/#pre-requisites","text":"Get the code git clone https : // github . com / Microsoft / mu_pip_build . git Install development dependencies pip install --upgrade -r requirements.txt Uninstall any copy of mu_build pip uninstall mu_build Install from local source (run command from root of repo) pip install - e .","title":"Pre-Requisites"},{"location":"dyn/mu_pip_build/developing/#testing","text":"Run a Basic Syntax/Lint Check (using flake8) and resolve any issues flake8 MuBuild Info Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run pytest with coverage data collected pytest - v --junitxml=test.junit.xml --html=pytest_MuBuild_report.html --self-contained-html --cov=MuBuild --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_MuBuild_report.html cov_html/index.html","title":"Testing"},{"location":"dyn/mu_pip_build/publishing/","text":"Publishing Project Mu Pip Build \u00b6 The MuBuild is published as a pypi (pip) module. The pip module is named mu_build . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here. Steps \u00b6 Info These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and check. Update the readme with info on changes for this version. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released. Tag format is v . . Do the release process (Use the server process for this but for documentation sake these are the steps) Install tools pip install --upgrade -r requirements.publisher.txt Build a wheel python setup . py sdist bdist_wheel Confirm wheel version is aligned with git tag ConfirmVersionAndTag . py Publish the wheel/distribution to pypi twine upload dist /*","title":"publishing"},{"location":"dyn/mu_pip_build/publishing/#publishing-project-mu-pip-build","text":"The MuBuild is published as a pypi (pip) module. The pip module is named mu_build . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here.","title":"Publishing Project Mu Pip Build"},{"location":"dyn/mu_pip_build/publishing/#steps","text":"Info These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and check. Update the readme with info on changes for this version. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released. Tag format is v . . Do the release process (Use the server process for this but for documentation sake these are the steps) Install tools pip install --upgrade -r requirements.publisher.txt Build a wheel python setup . py sdist bdist_wheel Confirm wheel version is aligned with git tag ConfirmVersionAndTag . py Publish the wheel/distribution to pypi twine upload dist /*","title":"Steps"},{"location":"dyn/mu_pip_build/using/","text":"Using Project Mu Pip Build \u00b6 Install from pip pip install mu_build Usage Docs \u00b6 TBD","title":"using"},{"location":"dyn/mu_pip_build/using/#using-project-mu-pip-build","text":"Install from pip pip install mu_build","title":"Using Project Mu Pip Build"},{"location":"dyn/mu_pip_build/using/#usage-docs","text":"TBD","title":"Usage Docs"},{"location":"dyn/mu_pip_environment/RepoDetails/","text":"Project Mu Pip Environment \u00b6 Git Details Repository Url: https://github.com/Microsoft/mu_pip_environment.git Branch: master Commit: 9caeb25d9574467f0ea029e3a3f580213ca0871a Commit Date: 2019-09-27 18:14:44 +0000 Entry point into Self Describing Environment (SDE). Sets up and parses state of workspace before calling into build. More Info \u00b6 Please see the Project Mu docs ( https://github.com/Microsoft/mu ) for more information. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Issues \u00b6 Please open any issues in the Project Mu GitHub tracker. More Details Contributing Code or Docs \u00b6 Please follow the general Project Mu Pull Request process. More Details Additionally make sure all testing described in the \"Development\" section passes. Using \u00b6 Usage Details Development \u00b6 Development Details Publish \u00b6 Publish Details Copyright & License \u00b6 Copyright \u00a9 2018, Microsoft Corporation All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Repo Details"},{"location":"dyn/mu_pip_environment/RepoDetails/#project-mu-pip-environment","text":"Git Details Repository Url: https://github.com/Microsoft/mu_pip_environment.git Branch: master Commit: 9caeb25d9574467f0ea029e3a3f580213ca0871a Commit Date: 2019-09-27 18:14:44 +0000 Entry point into Self Describing Environment (SDE). Sets up and parses state of workspace before calling into build.","title":"Project Mu Pip Environment"},{"location":"dyn/mu_pip_environment/RepoDetails/#more-info","text":"Please see the Project Mu docs ( https://github.com/Microsoft/mu ) for more information. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"More Info"},{"location":"dyn/mu_pip_environment/RepoDetails/#issues","text":"Please open any issues in the Project Mu GitHub tracker. More Details","title":"Issues"},{"location":"dyn/mu_pip_environment/RepoDetails/#contributing-code-or-docs","text":"Please follow the general Project Mu Pull Request process. More Details Additionally make sure all testing described in the \"Development\" section passes.","title":"Contributing Code or Docs"},{"location":"dyn/mu_pip_environment/RepoDetails/#using","text":"Usage Details","title":"Using"},{"location":"dyn/mu_pip_environment/RepoDetails/#development","text":"Development Details","title":"Development"},{"location":"dyn/mu_pip_environment/RepoDetails/#publish","text":"Publish Details","title":"Publish"},{"location":"dyn/mu_pip_environment/RepoDetails/#copyright-license","text":"Copyright \u00a9 2018, Microsoft Corporation All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Copyright &amp; License"},{"location":"dyn/mu_pip_environment/developing/","text":"Developing Project Mu Pip Environment \u00b6 Pre-Requisites \u00b6 Get the code git clone https : // github . com / Microsoft / mu_pip_environment . git Install development dependencies pip install --upgrade -r requirements.txt Uninstall any copy of mu_environment pip uninstall mu_environment Install from local source (run command from root of repo) pip install - e . Testing \u00b6 Run a Basic Syntax/Lint Check (using flake8) and resolve any issues flake8 MuEnvironment Info Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run pytest with coverage data collected pytest - v --junitxml=test.junit.xml --html=pytest_MuEnvironment_report.html --self-contained-html --cov=MuEnvironment --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_MuEnvironment_report.html cov_html/index.html","title":"developing"},{"location":"dyn/mu_pip_environment/developing/#developing-project-mu-pip-environment","text":"","title":"Developing Project Mu Pip Environment"},{"location":"dyn/mu_pip_environment/developing/#pre-requisites","text":"Get the code git clone https : // github . com / Microsoft / mu_pip_environment . git Install development dependencies pip install --upgrade -r requirements.txt Uninstall any copy of mu_environment pip uninstall mu_environment Install from local source (run command from root of repo) pip install - e .","title":"Pre-Requisites"},{"location":"dyn/mu_pip_environment/developing/#testing","text":"Run a Basic Syntax/Lint Check (using flake8) and resolve any issues flake8 MuEnvironment Info Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run pytest with coverage data collected pytest - v --junitxml=test.junit.xml --html=pytest_MuEnvironment_report.html --self-contained-html --cov=MuEnvironment --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_MuEnvironment_report.html cov_html/index.html","title":"Testing"},{"location":"dyn/mu_pip_environment/publishing/","text":"Publishing Project Mu Pip Environment \u00b6 The MuEnvironment is published as a pypi (pip) module. The pip module is named mu_environment . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here. Steps \u00b6 Info These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and check. Update the readme with info on changes for this version. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released. Tag format is v . . Do the release process Install tools pip install --upgrade -r requirements.publisher.txt Build a wheel python setup . py sdist bdist_wheel Confirm wheel version is aligned with git tag ConfirmVersionAndTag . py Publish the wheel/distribution to pypi twine upload dist /*","title":"publishing"},{"location":"dyn/mu_pip_environment/publishing/#publishing-project-mu-pip-environment","text":"The MuEnvironment is published as a pypi (pip) module. The pip module is named mu_environment . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here.","title":"Publishing Project Mu Pip Environment"},{"location":"dyn/mu_pip_environment/publishing/#steps","text":"Info These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and check. Update the readme with info on changes for this version. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released. Tag format is v . . Do the release process Install tools pip install --upgrade -r requirements.publisher.txt Build a wheel python setup . py sdist bdist_wheel Confirm wheel version is aligned with git tag ConfirmVersionAndTag . py Publish the wheel/distribution to pypi twine upload dist /*","title":"Steps"},{"location":"dyn/mu_pip_environment/using/","text":"Using Project Mu Pip Environment \u00b6 Install from pip pip install mu_environment Usage Docs \u00b6 TBD","title":"using"},{"location":"dyn/mu_pip_environment/using/#using-project-mu-pip-environment","text":"Install from pip pip install mu_environment","title":"Using Project Mu Pip Environment"},{"location":"dyn/mu_pip_environment/using/#usage-docs","text":"TBD","title":"Usage Docs"},{"location":"dyn/mu_pip_environment/MuEnvironment/bin/readme/","text":"The binary files that will be included with this package \u00b6","title":"bin"},{"location":"dyn/mu_pip_environment/MuEnvironment/bin/readme/#the-binary-files-that-will-be-included-with-this-package","text":"","title":"The binary files that will be included with this package"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_MuLogging/","text":"Mu Logging \u00b6 MuLogging is a collection of utilities to manage logging in Project Mu. There are four different ways to create handlers. 1. setup_txt_logger - a handler that outputs a txt file 2. setup_markdown_logger - a handler that outputs a markdown file with an output file 3. setup_console_logging - a handler that logs to the console with optional colors 4. create_output_stream - a handler that has an in-memory stream that you can later read from setup_logging is a helper function that creates 1-3 of the handlers. The output_stream is used for plugins in mu_build so they can keep track of compiler output General Practice \u00b6 All modules that are not PlatformBuilder or MuBuild should request a named logger like this: logging . getLogger ( \"MuGit\" ) Modules that are not the root module get downgraded a level (ie. critical -> warning)","title":"feature Mu Logging"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_MuLogging/#mu-logging","text":"MuLogging is a collection of utilities to manage logging in Project Mu. There are four different ways to create handlers. 1. setup_txt_logger - a handler that outputs a txt file 2. setup_markdown_logger - a handler that outputs a markdown file with an output file 3. setup_console_logging - a handler that logs to the console with optional colors 4. create_output_stream - a handler that has an in-memory stream that you can later read from setup_logging is a helper function that creates 1-3 of the handlers. The output_stream is used for plugins in mu_build so they can keep track of compiler output","title":"Mu Logging"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_MuLogging/#general-practice","text":"All modules that are not PlatformBuilder or MuBuild should request a named logger like this: logging . getLogger ( \"MuGit\" ) Modules that are not the root module get downgraded a level (ie. critical -> warning)","title":"General Practice"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/","text":"External Dependencies \u00b6 Overview \u00b6 External dependencies are a way within the build environment to describe external dependencies and have the build system fetch them when doing the setup or update operations. Ext_dep state will also be verified when doing a build to ensure the environment is in the required state prior to building. Ext_deps have solved three major issues for Project Mu. Binaries causing bloat of git repositories Conditional inclusion of a dependency (only for certain usages) Reproducability and tracking of dependencies Why \u00b6 Git Bloat \u00b6 Best practices advise against checking in binaries to git repositories as the overall size of git repos will balloon quickly causing slow clones and slow operations. Building firmware often requires custom tools, firmware blobs, or other binaries and it is critical these are maintained and versioned with the repository. Package management tools can solve the hosting of these binaries but edk2 has no built in tool to track them, extract them, etc. Ext_deps provide that mechanism. Conditional Inclusion (scopes) \u00b6 Ext_deps leverage the environment scope concept so that a repository can carry ext_deps that are only used in some conditions. Scopes are a string that a environment envoking tool uses to indicate what ext_deps should be used. These scopes are loosly based on functionality. Reproducability and Tracking \u00b6 Ext_deps are common infrastructure so that all external dependencies can be handled consistantly. Versions are added to the version report so that for any given operation (like build) a complete list of what was used is available. This makes tracking versions consistant and \"free\". Ext_deps when fetched will update their state. If the repository is updated to include a new ext_dep version the tool will be told the environment state is not valid and can then enforce thet user updates their environment. Examples of Usage \u00b6 Here are a few examples where ext_deps have been found useful: An ext_dep describing a test repository that is only needed when running unit tests. By leveraging scopes this ext_dep is only fetched when the unittest scope is active. Similiar to the unit test dependency, support for CI builds often require unique dependencies. When doing a CI build of a core repository it might have critical dependencies that need to be fetched but when the core repository is included within a platform repository as a dependency, then the core would defer to the platform as to how to include the dependency. An ext_dep describing the compiler toolchain. This ext_dep is only needed when a builder is using that toolchain for that target type. An ext_dep describing some platform binary. This is only needed when building that given platform and since git is not optiized to handle binaries this saves a lot of unnecessary bloat in the repository. Supported Types \u00b6 NuGet Dependency \u00b6 Nuget dependency is used to fetch files from a nuget feed. This feed can be either unauthenticated or authenticated. Support is done by using the nuget command line tool. When the ext_dep type is set to nuget the descriptor will be intrepreted as a nuget dependency. Nuget has a few nice features such as caching, authentication, versioning, and is platform and language agnostic. Web Dependency \u00b6 Web dependency is used to describe a dependency on an asset that can be downloaded via a URL and a web request. It will download whatever is located at the source URL and can support single files, compressed files, and folders. When the ext_dep type is set to web the ext_dep will be intrepreted as a web dependency. Git Dependency \u00b6 Git dependency is used to describe a dependency on a git repository. This repository will be cloned to the ext_dep location and the version will be checked out. For this ext_dep descriptor the type is git . A git dependency should be treated as read-only because the verify and clean phase will do destructive operations where local changes would be destroyed. Developer Note \u00b6 To create a new Dependency type it requires a new subclass of the ExternalDependency class. The subclass needs to have a type field and then factory method in ExternalDependency . py needs to be updated to create new instances of the new type. How they work \u00b6 Ext_deps are found by the SDE (self-describing environment). If you have any questions about that, go review the document for that. Once the ext_dep is found it can be interacted with depending on use case/tool. Objects created with the data from ext_dep descriptors and are subclassed according to the \"type\" field in the descriptor. These objects contain the code for fetching, validating, updating, and cleaning dependency objects and metadata. When referenced from the SDE itself, they can also update paths and other build/shell vars in the build environment. How to create/use an ext_dep \u00b6 An ext_dep is defined by a json file that ends in _ext_dep.json It must follow the schema outlined below. It will be unpacked in a new folder in the same directory as the .json file in a folder named {name}_extdep. We strongly recommend adding any folder that ends in _extdep to your repositories gitignore. It would look like this: * _extdep / Ext_Dep Example json file { \"scope\" : \"cibuild\" , \"type\" : \"nuget\" , \"name\" : \"iasl\" , \"source\" : \"https://api.nuget.org/v3/index.json\" , \"version\" : \"20190215.0.0\" , \"flags\" : [ \"set_path\" , \"host_specific\" ] } The base schema \u00b6 Required \u00b6 scope: (required) (string) - name of scope when this ext_dep should be evaluated - type: (required) (string from list of known types) - See above for types - name: This is the name of the ext_dep and will be part of the path where the ext_dep is unpacked - source: see per type - version: see per type - flags: Optional conditions that can be applied. Can be empty list Optional \u00b6 id: (string) - Identifier allowing override feature - Must be unique override_id: (string) - Identifier of the ext_dep this should replace (allows for changing an ext_dep in another source by id) var_name: TODO Nuget Type Schema differences \u00b6 source: This should be the nuget feed URL version: nuget version. Generally xx.yy.zz For this type there are zero additional ext_dep fields. Web Type Schema differences \u00b6 source: url to download version: only used for folder naming For this type there are three additional ext_dep fields: internal_path (required) This describes the internal structure of whatever we are downloading . If you are just downloading a file , include the name you would like the file to be . If you are downloading a directory , indicate so with a / before the path . The folder the path points to will have it ' s contents copied into the final name_ext_dep folder. compression_type (optional) Including this field is indicating that the file being downloaded is compressed and that you would like the contents of internal_path to be extracted . If you have a compressed file and would not like it to be decompressed , omit this field . Currently tar and zip files are supported . If the file is not compressed , omit this field . sha256 (optional) If desired , you can provide the hash of your file . This hash will be checked against what is being downloaded to ensure it is valid . It is strongly recommended to use this to ensure the contents are as expected . Git Type Schema Differences \u00b6 source: url of git repo version: commit hash to checkout Experimental Option: url_creds_var \u00b6 If this field is found in the descriptor file when initializing this extdep, the string value listed will be checked against the environment's shell_vars. If a matching var is found, this string in the shell_var will be prepended to the URL host for the source URL. NOTE: This is intended for server builds and may be subject to change as we figure out how it fits into build flows. Also note that any creds passed may end up in build logs and other server-side artifacts. Use with caution! Example: TEST_DESCRIPTOR = { \"scope\" : \"global\" , \"type\" : \"git\" , \"name\" : \"ExampleRepo\" , \"source\" : \"http://example.com/path/to/repo.git\" , \"version\" : \"7fd1a60b01f91b314f59955a4e4d4e80d8edf11d\" , \"url_creds_var\" : 'my_url_creds' \"flags\" : [] } # Populate shell var. env . set_shell_var ( 'my_url_creds' , 'my_user:my_pass' ) # URL cloned by the GitDependency object will look like... final_url = 'http://my_user:my_pass@example.com/path/to/repo.git' The Flags \u00b6 There are specific flags that do different things. Flags are defined by MuEnviroment and cannot be modified without updating the pip module. More information on the flags can be found in the SDE documentation.","title":"feature extdep"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#external-dependencies","text":"","title":"External Dependencies"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#overview","text":"External dependencies are a way within the build environment to describe external dependencies and have the build system fetch them when doing the setup or update operations. Ext_dep state will also be verified when doing a build to ensure the environment is in the required state prior to building. Ext_deps have solved three major issues for Project Mu. Binaries causing bloat of git repositories Conditional inclusion of a dependency (only for certain usages) Reproducability and tracking of dependencies","title":"Overview"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#why","text":"","title":"Why"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#git-bloat","text":"Best practices advise against checking in binaries to git repositories as the overall size of git repos will balloon quickly causing slow clones and slow operations. Building firmware often requires custom tools, firmware blobs, or other binaries and it is critical these are maintained and versioned with the repository. Package management tools can solve the hosting of these binaries but edk2 has no built in tool to track them, extract them, etc. Ext_deps provide that mechanism.","title":"Git Bloat"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#conditional-inclusion-scopes","text":"Ext_deps leverage the environment scope concept so that a repository can carry ext_deps that are only used in some conditions. Scopes are a string that a environment envoking tool uses to indicate what ext_deps should be used. These scopes are loosly based on functionality.","title":"Conditional Inclusion (scopes)"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#reproducability-and-tracking","text":"Ext_deps are common infrastructure so that all external dependencies can be handled consistantly. Versions are added to the version report so that for any given operation (like build) a complete list of what was used is available. This makes tracking versions consistant and \"free\". Ext_deps when fetched will update their state. If the repository is updated to include a new ext_dep version the tool will be told the environment state is not valid and can then enforce thet user updates their environment.","title":"Reproducability and Tracking"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#examples-of-usage","text":"Here are a few examples where ext_deps have been found useful: An ext_dep describing a test repository that is only needed when running unit tests. By leveraging scopes this ext_dep is only fetched when the unittest scope is active. Similiar to the unit test dependency, support for CI builds often require unique dependencies. When doing a CI build of a core repository it might have critical dependencies that need to be fetched but when the core repository is included within a platform repository as a dependency, then the core would defer to the platform as to how to include the dependency. An ext_dep describing the compiler toolchain. This ext_dep is only needed when a builder is using that toolchain for that target type. An ext_dep describing some platform binary. This is only needed when building that given platform and since git is not optiized to handle binaries this saves a lot of unnecessary bloat in the repository.","title":"Examples of Usage"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#supported-types","text":"","title":"Supported Types"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#nuget-dependency","text":"Nuget dependency is used to fetch files from a nuget feed. This feed can be either unauthenticated or authenticated. Support is done by using the nuget command line tool. When the ext_dep type is set to nuget the descriptor will be intrepreted as a nuget dependency. Nuget has a few nice features such as caching, authentication, versioning, and is platform and language agnostic.","title":"NuGet Dependency"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#web-dependency","text":"Web dependency is used to describe a dependency on an asset that can be downloaded via a URL and a web request. It will download whatever is located at the source URL and can support single files, compressed files, and folders. When the ext_dep type is set to web the ext_dep will be intrepreted as a web dependency.","title":"Web Dependency"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#git-dependency","text":"Git dependency is used to describe a dependency on a git repository. This repository will be cloned to the ext_dep location and the version will be checked out. For this ext_dep descriptor the type is git . A git dependency should be treated as read-only because the verify and clean phase will do destructive operations where local changes would be destroyed.","title":"Git Dependency"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#developer-note","text":"To create a new Dependency type it requires a new subclass of the ExternalDependency class. The subclass needs to have a type field and then factory method in ExternalDependency . py needs to be updated to create new instances of the new type.","title":"Developer Note"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#how-they-work","text":"Ext_deps are found by the SDE (self-describing environment). If you have any questions about that, go review the document for that. Once the ext_dep is found it can be interacted with depending on use case/tool. Objects created with the data from ext_dep descriptors and are subclassed according to the \"type\" field in the descriptor. These objects contain the code for fetching, validating, updating, and cleaning dependency objects and metadata. When referenced from the SDE itself, they can also update paths and other build/shell vars in the build environment.","title":"How they work"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#how-to-createuse-an-ext_dep","text":"An ext_dep is defined by a json file that ends in _ext_dep.json It must follow the schema outlined below. It will be unpacked in a new folder in the same directory as the .json file in a folder named {name}_extdep. We strongly recommend adding any folder that ends in _extdep to your repositories gitignore. It would look like this: * _extdep / Ext_Dep Example json file { \"scope\" : \"cibuild\" , \"type\" : \"nuget\" , \"name\" : \"iasl\" , \"source\" : \"https://api.nuget.org/v3/index.json\" , \"version\" : \"20190215.0.0\" , \"flags\" : [ \"set_path\" , \"host_specific\" ] }","title":"How to create/use an ext_dep"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#the-base-schema","text":"","title":"The base schema"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#required","text":"scope: (required) (string) - name of scope when this ext_dep should be evaluated - type: (required) (string from list of known types) - See above for types - name: This is the name of the ext_dep and will be part of the path where the ext_dep is unpacked - source: see per type - version: see per type - flags: Optional conditions that can be applied. Can be empty list","title":"Required"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#optional","text":"id: (string) - Identifier allowing override feature - Must be unique override_id: (string) - Identifier of the ext_dep this should replace (allows for changing an ext_dep in another source by id) var_name: TODO","title":"Optional"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#nuget-type-schema-differences","text":"source: This should be the nuget feed URL version: nuget version. Generally xx.yy.zz For this type there are zero additional ext_dep fields.","title":"Nuget Type Schema differences"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#web-type-schema-differences","text":"source: url to download version: only used for folder naming For this type there are three additional ext_dep fields: internal_path (required) This describes the internal structure of whatever we are downloading . If you are just downloading a file , include the name you would like the file to be . If you are downloading a directory , indicate so with a / before the path . The folder the path points to will have it ' s contents copied into the final name_ext_dep folder. compression_type (optional) Including this field is indicating that the file being downloaded is compressed and that you would like the contents of internal_path to be extracted . If you have a compressed file and would not like it to be decompressed , omit this field . Currently tar and zip files are supported . If the file is not compressed , omit this field . sha256 (optional) If desired , you can provide the hash of your file . This hash will be checked against what is being downloaded to ensure it is valid . It is strongly recommended to use this to ensure the contents are as expected .","title":"Web Type Schema differences"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#git-type-schema-differences","text":"source: url of git repo version: commit hash to checkout","title":"Git Type Schema Differences"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#experimental-option-url_creds_var","text":"If this field is found in the descriptor file when initializing this extdep, the string value listed will be checked against the environment's shell_vars. If a matching var is found, this string in the shell_var will be prepended to the URL host for the source URL. NOTE: This is intended for server builds and may be subject to change as we figure out how it fits into build flows. Also note that any creds passed may end up in build logs and other server-side artifacts. Use with caution! Example: TEST_DESCRIPTOR = { \"scope\" : \"global\" , \"type\" : \"git\" , \"name\" : \"ExampleRepo\" , \"source\" : \"http://example.com/path/to/repo.git\" , \"version\" : \"7fd1a60b01f91b314f59955a4e4d4e80d8edf11d\" , \"url_creds_var\" : 'my_url_creds' \"flags\" : [] } # Populate shell var. env . set_shell_var ( 'my_url_creds' , 'my_user:my_pass' ) # URL cloned by the GitDependency object will look like... final_url = 'http://my_user:my_pass@example.com/path/to/repo.git'","title":"Experimental Option: url_creds_var"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_extdep/#the-flags","text":"There are specific flags that do different things. Flags are defined by MuEnviroment and cannot be modified without updating the pip module. More information on the flags can be found in the SDE documentation.","title":"The Flags"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_nugetpublishing/","text":"NugetPublishing \u00b6 Tool to help create and publish nuget packages for Project Mu resources Usage \u00b6 See NugetPublishing -h OPTIONAL: host_specific folders \u00b6 The possible different setups for the host are: OS: Linux, Windows, Java Architecture: x86 or ARM Highest Order Bit: 32 or 64 Before the path to the NuGet package contents is published, the Python environment can look inside at several sub-folders and decide which one to use based on the Host OS, highest order bit available, and the architecture of the processor. To do so, add \"host_specific\" to your flags like so: \"flags\" : [ \"host_specific\" ], If this flag is present, the environment will make a list possible sub-folders that would be acceptable for the host machine. For this example, a 64 bit Windows machine with an x86 processor was used: Windows-x86-64 Windows-x86 Windows-64 x86-64 Windows x86 64 The environment will look for these folders, following this order, and select the first one it finds. If none are found, the flag will be ignored. Authentication \u00b6 For publishing most service providers require authentication. The --ApiKey parameter allows the caller to supply a unique key for authorization. There are numerous ways to authenticate. For example Azure Dev Ops: VSTS credential manager. In an interactive session a dialog will popup for the user to login Tokens can also be used as the API key. Go to your account page to generate a token that can push packages NuGet.org Must use an API key. Go to your account page and generate a key. Pushing to an Authenticated Stream \u00b6 Previously the VsCredentialProvider was packaged right next to Nuget.exe and it was automatically found. If you have a specific credential provider executable needed to push to your stream, you'll need to follow the instructions here to make the executable available to find. You can add it to %LocalAppData%\\NuGet\\CredentialProvider or you can add an environmental variable NUGET_CREDENTIALPROVIDERS_PATH with the location of your provider. If you have multiple, they can be semicolon seperated. Example: Creating new config file for first use \u00b6 This will create the config files and place them in the current directory: NugetPublishing --Operation New --Name iasl --Author ProjectMu --ConfigFileFolderPath . --Description \"Description of item.\" --FeedUrl https://api.nuget.org/v3/index.json --ProjectUrl http://aka.ms/projectmu --LicenseType BSD2 For help run: NugetPublishing --Operation New --help Example: Publishing new version of tool \u00b6 Using an existing config file publish a new iasl.exe. See the example file iasl.config.json Download version from acpica.org Unzip Make a new folder (for my example I will call it \"new\") Copy the assets to publish into this new folder (in this case just iasl.exe) Run the iasl.exe -v command to see the version. Open cmd prompt in the NugetPublishing dir Pack and push (here is my example command. ) NugetPublishing --Operation PackAndPush --ConfigFilePath iasl.config.json --Version 20180209.0.0 --InputFolderPath \"C:\\temp\\iasl-win-20180209\\new\" --ApiKey <your key here>","title":"feature nugetpublishing"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_nugetpublishing/#nugetpublishing","text":"Tool to help create and publish nuget packages for Project Mu resources","title":"NugetPublishing"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_nugetpublishing/#usage","text":"See NugetPublishing -h","title":"Usage"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_nugetpublishing/#optional-host_specific-folders","text":"The possible different setups for the host are: OS: Linux, Windows, Java Architecture: x86 or ARM Highest Order Bit: 32 or 64 Before the path to the NuGet package contents is published, the Python environment can look inside at several sub-folders and decide which one to use based on the Host OS, highest order bit available, and the architecture of the processor. To do so, add \"host_specific\" to your flags like so: \"flags\" : [ \"host_specific\" ], If this flag is present, the environment will make a list possible sub-folders that would be acceptable for the host machine. For this example, a 64 bit Windows machine with an x86 processor was used: Windows-x86-64 Windows-x86 Windows-64 x86-64 Windows x86 64 The environment will look for these folders, following this order, and select the first one it finds. If none are found, the flag will be ignored.","title":"OPTIONAL: host_specific folders"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_nugetpublishing/#authentication","text":"For publishing most service providers require authentication. The --ApiKey parameter allows the caller to supply a unique key for authorization. There are numerous ways to authenticate. For example Azure Dev Ops: VSTS credential manager. In an interactive session a dialog will popup for the user to login Tokens can also be used as the API key. Go to your account page to generate a token that can push packages NuGet.org Must use an API key. Go to your account page and generate a key.","title":"Authentication"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_nugetpublishing/#pushing-to-an-authenticated-stream","text":"Previously the VsCredentialProvider was packaged right next to Nuget.exe and it was automatically found. If you have a specific credential provider executable needed to push to your stream, you'll need to follow the instructions here to make the executable available to find. You can add it to %LocalAppData%\\NuGet\\CredentialProvider or you can add an environmental variable NUGET_CREDENTIALPROVIDERS_PATH with the location of your provider. If you have multiple, they can be semicolon seperated.","title":"Pushing to an Authenticated Stream"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_nugetpublishing/#example-creating-new-config-file-for-first-use","text":"This will create the config files and place them in the current directory: NugetPublishing --Operation New --Name iasl --Author ProjectMu --ConfigFileFolderPath . --Description \"Description of item.\" --FeedUrl https://api.nuget.org/v3/index.json --ProjectUrl http://aka.ms/projectmu --LicenseType BSD2 For help run: NugetPublishing --Operation New --help","title":"Example: Creating new config file for first use"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_nugetpublishing/#example-publishing-new-version-of-tool","text":"Using an existing config file publish a new iasl.exe. See the example file iasl.config.json Download version from acpica.org Unzip Make a new folder (for my example I will call it \"new\") Copy the assets to publish into this new folder (in this case just iasl.exe) Run the iasl.exe -v command to see the version. Open cmd prompt in the NugetPublishing dir Pack and push (here is my example command. ) NugetPublishing --Operation PackAndPush --ConfigFilePath iasl.config.json --Version 20180209.0.0 --InputFolderPath \"C:\\temp\\iasl-win-20180209\\new\" --ApiKey <your key here>","title":"Example: Publishing new version of tool"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/","text":"Omnicache \u00b6 Omnicache, the tool, is a command line tool that helps setup and update a Project Mu Omnicache. An Omnicache is just a bare repo with lots of remotes fetched so that if configured the Project Mu tools will use it as a reference when updating or cloning a repo. This saves a lot of network bandwidth, disk space, and time if you develop with many workspaces on a single PC and can also be used to speed up CI. Creating your Omnicache \u00b6 You can setup your Omnicache many ways. You can add config entries from numerous files or thru command line. Try Omnicache - h for help. Here are the steps for a simple empty installation. Make sure you have installed mu_environment using Pip Open cmd prompt Create one omnicache --init <path> At the end of the creation it will suggest setting the OMNICACHE_PATH environment variable. For best results do this. Adding Config Entries \u00b6 Config entries can be added when first creating the cache as well as any time by using the tool. Config entries can be added 1-by-1 from the command line or thru a config file. Example of adding config entry \u00b6 omnicache - a tianocore_edk2 https : // github . com / tianocore / edk2 . git --init %OMNICACHE_PATH% omnicache - a openssl https : // github . com / openssl / openssl . git True --init %OMNICACHE_PATH% Example Config for Project Mu repos \u00b6 Copy the below sample and save it as abc.yml remotes : - name : mu_basecore url : https : // github . com / Microsoft / mu_basecore . git - name : common_mu url : https : // github . com / Microsoft / mu_plus . git - name : common_mu_tiano2 url : https : // github . com / Microsoft / mu_tiano_plus . git - name : mu_silicon_intel_tiano url : https : // github . com / Microsoft / mu_silicon_intel_tiano . git - name : mu_silicon_arm_tiano url : https : // github . com / Microsoft / mu_silicon_arm_tiano . git - name : mu_oem_sample url : https : // github . com / Microsoft / mu_oem_sample . git - name : openssl url : https : // github . com / openssl / openssl . git tag : true - name : tianocore_edk2 url : https : // github . com / tianocore / edk2 . git Then run omnicache command to add the new entries. omnicache - c abc . yml --init %OMNICACHE_PATH% Keeping your Omnicache Current \u00b6 The Omnicache doesn't have to always be current. If it gets stale it will still help but there will be more \"cache misses\". Since the Omnicache is just a git repo it can easily be updated by running git commands and since it is a bare repo it is trouble free to update. The Omicache tool attempts to make this even easier. Windows Scheduled Task \u00b6 If you want to use a scheduled task here is one way to do it on Windows. Set the OMNICACHE_PATH environment variable to your path Create an omnicache_update.bat file in your omnicache directory that contains omnicache --init --fetch %OMNICACHE_PATH% Create a temporary XML file on your desktop with the contents below named \"O_U.xml\" <?xml version=\"1.0\" encoding=\"UTF-16\"?> <Task version= \"1.4\" xmlns= \"http://schemas.microsoft.com/windows/2004/02/mit/task\" > <Triggers> <CalendarTrigger> <StartBoundary> 2019-01-04T8:00:00 </StartBoundary> <ExecutionTimeLimit> PT2H </ExecutionTimeLimit> <Enabled> true </Enabled> <ScheduleByDay> <DaysInterval> 1 </DaysInterval> </ScheduleByDay> </CalendarTrigger> </Triggers> <Settings> <MultipleInstancesPolicy> IgnoreNew </MultipleInstancesPolicy> <DisallowStartIfOnBatteries> false </DisallowStartIfOnBatteries> <StopIfGoingOnBatteries> false </StopIfGoingOnBatteries> <AllowHardTerminate> true </AllowHardTerminate> <StartWhenAvailable> false </StartWhenAvailable> <RunOnlyIfNetworkAvailable> false </RunOnlyIfNetworkAvailable> <IdleSettings> <StopOnIdleEnd> true </StopOnIdleEnd> <RestartOnIdle> false </RestartOnIdle> </IdleSettings> <AllowStartOnDemand> true </AllowStartOnDemand> <Enabled> true </Enabled> <Hidden> false </Hidden> <RunOnlyIfIdle> false </RunOnlyIfIdle> <DisallowStartOnRemoteAppSession> false </DisallowStartOnRemoteAppSession> <UseUnifiedSchedulingEngine> true </UseUnifiedSchedulingEngine> <WakeToRun> false </WakeToRun> <ExecutionTimeLimit> PT72H </ExecutionTimeLimit> <Priority> 7 </Priority> </Settings> <Actions Context= \"Author\" > <Exec> <Command> cmd.exe </Command> <Arguments> /c omnicache_update.bat </Arguments> <WorkingDirectory> %OMNICACHE_PATH% </WorkingDirectory> </Exec> </Actions> </Task> Open Cmd prompt and use SCHTASKS to create a task. SCHTASKS / Create / XML \"O_U.xml\" / TN \"Omnicache Updater\" Using Omnicache for update \u00b6 Set the environment variable OMNICACHE_PATH for automatic usage. Project Mu tools when running platformbuild . py --setup or platformbuild . py --update will use the cache. Using Omnicache for git clone \u00b6 Current best practice is to setup a bashrc alias if using git for windows in gitbash. alias gcl = ' git clone --reference ${ OMNICACHE_PATH } \u2019 Then every git clone you want to do you can call gcl < url > < folder > instead of git clone < url > < folder > Warnings \u00b6 Removing the omnicache from your PC can cause problems in your repos. Read up on --reference in git for methods to resolve this before deleting the omnicache. Bug in git submodule update --recursive --reference <path> . This doesn't work as git appends the recursive submodule path to the reference path. Contacting git maintainers for clarity. Tags: tags are not namespaced by remote therefore conflicts could occur. Suggestion is to not pull tags unless required. Stack exchange has a few other ideas but nothing implemented yet. Older versions of the omnicache tool used - u true to update. Newer versions just require - u or --fetch . Since - a is a varable length argument list it is best to always add the --init parameter as the last parameter before the cache_dir positional argument. This way python argparse knows positional args from the - a optional args. A second tutorial of Omnicache \u00b6 The Omnicache or how I learned to stop worrying and love the allrepo \u00b6 The Genesis \u00b6 Many repos in the Project Mu tree have common roots and share a very similar codebase. In order to speed up clone times for our CI builds as well as for personal use, we realized you can clone a repo using a reference repository. git clone --reference ../some-directory Another feature that came to light is that you can use git to create an omnirepostitory. You can have all the objects stored into one place and git will query this repo for any objects it wishes to fetch and if they aren't found, it will then request them from upstream. We created some helper functions to wrap around this. It can be called by omnicache. Creating a new omnicache \u00b6 omnicache --init ../omnicache You can optionally use omnicache --new ../omnicache The difference between the two is that new will fail if something exists there, init does not. Feeding- I mean, Adding to the omnicache \u00b6 omnicache -a <name> <url> <Sync tags optional default = False> ../omnicache omnicache --add <name> <url> <Sync tags optional default = False> ../omnicache (Either of these will work) Updating the omnicache \u00b6 Now that you're a proud owner of an omnicache, you need to take care to update it semi-regularly. omnicache --update ../omnicache omnicache -u ../omnicache (Either of these will work) Know what's in the cache \u00b6 You can find out what is in your cache by listing it's contents. omnicache --list ../omnicache Assimilation into the Omnicache \u00b6 Sometimes you have a folder where all the repos are already cloned (either as submodules or separate folders). You can scan them all into the omnicache by using the scan feature. omnicache --scan ../folder ../omnicache This will add unique repos/submodules that it finds in the top level folders in ../folder. Unique is determined by URL. Fighting back against the Omnicache \u00b6 If your omnicache has grown a touch too powerful, you can take control back in your life by removing items from the cache. omnicache --remove ../omnicache omnicache -r ../omnicache Using the Omnicache \u00b6 Many of the tools in Project Mu are equipped to handle the omnicache and details on how to use them can be found in their respective documentations or help menus.","title":"feature omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#omnicache","text":"Omnicache, the tool, is a command line tool that helps setup and update a Project Mu Omnicache. An Omnicache is just a bare repo with lots of remotes fetched so that if configured the Project Mu tools will use it as a reference when updating or cloning a repo. This saves a lot of network bandwidth, disk space, and time if you develop with many workspaces on a single PC and can also be used to speed up CI.","title":"Omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#creating-your-omnicache","text":"You can setup your Omnicache many ways. You can add config entries from numerous files or thru command line. Try Omnicache - h for help. Here are the steps for a simple empty installation. Make sure you have installed mu_environment using Pip Open cmd prompt Create one omnicache --init <path> At the end of the creation it will suggest setting the OMNICACHE_PATH environment variable. For best results do this.","title":"Creating your Omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#adding-config-entries","text":"Config entries can be added when first creating the cache as well as any time by using the tool. Config entries can be added 1-by-1 from the command line or thru a config file.","title":"Adding Config Entries"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#example-of-adding-config-entry","text":"omnicache - a tianocore_edk2 https : // github . com / tianocore / edk2 . git --init %OMNICACHE_PATH% omnicache - a openssl https : // github . com / openssl / openssl . git True --init %OMNICACHE_PATH%","title":"Example of adding config entry"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#example-config-for-project-mu-repos","text":"Copy the below sample and save it as abc.yml remotes : - name : mu_basecore url : https : // github . com / Microsoft / mu_basecore . git - name : common_mu url : https : // github . com / Microsoft / mu_plus . git - name : common_mu_tiano2 url : https : // github . com / Microsoft / mu_tiano_plus . git - name : mu_silicon_intel_tiano url : https : // github . com / Microsoft / mu_silicon_intel_tiano . git - name : mu_silicon_arm_tiano url : https : // github . com / Microsoft / mu_silicon_arm_tiano . git - name : mu_oem_sample url : https : // github . com / Microsoft / mu_oem_sample . git - name : openssl url : https : // github . com / openssl / openssl . git tag : true - name : tianocore_edk2 url : https : // github . com / tianocore / edk2 . git Then run omnicache command to add the new entries. omnicache - c abc . yml --init %OMNICACHE_PATH%","title":"Example Config for Project Mu repos"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#keeping-your-omnicache-current","text":"The Omnicache doesn't have to always be current. If it gets stale it will still help but there will be more \"cache misses\". Since the Omnicache is just a git repo it can easily be updated by running git commands and since it is a bare repo it is trouble free to update. The Omicache tool attempts to make this even easier.","title":"Keeping your Omnicache Current"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#windows-scheduled-task","text":"If you want to use a scheduled task here is one way to do it on Windows. Set the OMNICACHE_PATH environment variable to your path Create an omnicache_update.bat file in your omnicache directory that contains omnicache --init --fetch %OMNICACHE_PATH% Create a temporary XML file on your desktop with the contents below named \"O_U.xml\" <?xml version=\"1.0\" encoding=\"UTF-16\"?> <Task version= \"1.4\" xmlns= \"http://schemas.microsoft.com/windows/2004/02/mit/task\" > <Triggers> <CalendarTrigger> <StartBoundary> 2019-01-04T8:00:00 </StartBoundary> <ExecutionTimeLimit> PT2H </ExecutionTimeLimit> <Enabled> true </Enabled> <ScheduleByDay> <DaysInterval> 1 </DaysInterval> </ScheduleByDay> </CalendarTrigger> </Triggers> <Settings> <MultipleInstancesPolicy> IgnoreNew </MultipleInstancesPolicy> <DisallowStartIfOnBatteries> false </DisallowStartIfOnBatteries> <StopIfGoingOnBatteries> false </StopIfGoingOnBatteries> <AllowHardTerminate> true </AllowHardTerminate> <StartWhenAvailable> false </StartWhenAvailable> <RunOnlyIfNetworkAvailable> false </RunOnlyIfNetworkAvailable> <IdleSettings> <StopOnIdleEnd> true </StopOnIdleEnd> <RestartOnIdle> false </RestartOnIdle> </IdleSettings> <AllowStartOnDemand> true </AllowStartOnDemand> <Enabled> true </Enabled> <Hidden> false </Hidden> <RunOnlyIfIdle> false </RunOnlyIfIdle> <DisallowStartOnRemoteAppSession> false </DisallowStartOnRemoteAppSession> <UseUnifiedSchedulingEngine> true </UseUnifiedSchedulingEngine> <WakeToRun> false </WakeToRun> <ExecutionTimeLimit> PT72H </ExecutionTimeLimit> <Priority> 7 </Priority> </Settings> <Actions Context= \"Author\" > <Exec> <Command> cmd.exe </Command> <Arguments> /c omnicache_update.bat </Arguments> <WorkingDirectory> %OMNICACHE_PATH% </WorkingDirectory> </Exec> </Actions> </Task> Open Cmd prompt and use SCHTASKS to create a task. SCHTASKS / Create / XML \"O_U.xml\" / TN \"Omnicache Updater\"","title":"Windows Scheduled Task"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#using-omnicache-for-update","text":"Set the environment variable OMNICACHE_PATH for automatic usage. Project Mu tools when running platformbuild . py --setup or platformbuild . py --update will use the cache.","title":"Using Omnicache for update"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#using-omnicache-for-git-clone","text":"Current best practice is to setup a bashrc alias if using git for windows in gitbash. alias gcl = ' git clone --reference ${ OMNICACHE_PATH } \u2019 Then every git clone you want to do you can call gcl < url > < folder > instead of git clone < url > < folder >","title":"Using Omnicache for git clone"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#warnings","text":"Removing the omnicache from your PC can cause problems in your repos. Read up on --reference in git for methods to resolve this before deleting the omnicache. Bug in git submodule update --recursive --reference <path> . This doesn't work as git appends the recursive submodule path to the reference path. Contacting git maintainers for clarity. Tags: tags are not namespaced by remote therefore conflicts could occur. Suggestion is to not pull tags unless required. Stack exchange has a few other ideas but nothing implemented yet. Older versions of the omnicache tool used - u true to update. Newer versions just require - u or --fetch . Since - a is a varable length argument list it is best to always add the --init parameter as the last parameter before the cache_dir positional argument. This way python argparse knows positional args from the - a optional args.","title":"Warnings"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#a-second-tutorial-of-omnicache","text":"","title":"A second tutorial of Omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#the-omnicache-or-how-i-learned-to-stop-worrying-and-love-the-allrepo","text":"","title":"The Omnicache or how I learned to stop worrying and love the allrepo"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#the-genesis","text":"Many repos in the Project Mu tree have common roots and share a very similar codebase. In order to speed up clone times for our CI builds as well as for personal use, we realized you can clone a repo using a reference repository. git clone --reference ../some-directory Another feature that came to light is that you can use git to create an omnirepostitory. You can have all the objects stored into one place and git will query this repo for any objects it wishes to fetch and if they aren't found, it will then request them from upstream. We created some helper functions to wrap around this. It can be called by omnicache.","title":"The Genesis"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#creating-a-new-omnicache","text":"omnicache --init ../omnicache You can optionally use omnicache --new ../omnicache The difference between the two is that new will fail if something exists there, init does not.","title":"Creating a new omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#feeding-i-mean-adding-to-the-omnicache","text":"omnicache -a <name> <url> <Sync tags optional default = False> ../omnicache omnicache --add <name> <url> <Sync tags optional default = False> ../omnicache (Either of these will work)","title":"Feeding- I mean, Adding to the omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#updating-the-omnicache","text":"Now that you're a proud owner of an omnicache, you need to take care to update it semi-regularly. omnicache --update ../omnicache omnicache -u ../omnicache (Either of these will work)","title":"Updating the omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#know-whats-in-the-cache","text":"You can find out what is in your cache by listing it's contents. omnicache --list ../omnicache","title":"Know what's in the cache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#assimilation-into-the-omnicache","text":"Sometimes you have a folder where all the repos are already cloned (either as submodules or separate folders). You can scan them all into the omnicache by using the scan feature. omnicache --scan ../folder ../omnicache This will add unique repos/submodules that it finds in the top level folders in ../folder. Unique is determined by URL.","title":"Assimilation into the Omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#fighting-back-against-the-omnicache","text":"If your omnicache has grown a touch too powerful, you can take control back in your life by removing items from the cache. omnicache --remove ../omnicache omnicache -r ../omnicache","title":"Fighting back against the Omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_omnicache/#using-the-omnicache","text":"Many of the tools in Project Mu are equipped to handle the omnicache and details on how to use them can be found in their respective documentations or help menus.","title":"Using the Omnicache"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/","text":"Plugin Manager \u00b6 The Genesis \u00b6 Plugins are similar to external dependencies, in that they are defined by a Json file and they are discovered by the SDE. If you wish to learn more about the SDE, please go read the document about the self describing enviroment. They are defined by the EnvironmentDescriptorFiles which also describe external dependencies and path descriptors. Types of plugins \u00b6 Types of plugins are defined by the class they inherit from UefiBuildPlugin Contains two methods, Pre and Post Build. These methods are called on Pre and Post Build steps in UefiBuild (not MuBuild). There is no guarantee on ordering between different plugins (Pre will always come before Post). Post is will not run if there is a critical error in the build process. The idea here is to allow for custom, self-contained build functionality to be added without required UEFI build changes or inline code modifications. DscProcessorPlugin (in-progress) This is a plugin type that can apply transformations to the active DSC that will then be used to build the system. This is not production ready and not enabled in any builds currently. UefiHelperPlugin This is a helper plugin that publishes a function that can be used by other parts of the system. An example of this would be the Capsule signing system. This really is less about plugin design and more about keeping the UEFI build and platform builder python files minimal and getting the desired code reuse. MuBuildPlugin A plugin that runs during the main stage of MuBuild. The build step is actually a plugin so as ordering is not guranteed so you don't have any assurance that the build is successful or that the build has started How it works \u00b6 You might be asking yourself how does the sausage get made. In the name of sating curiosity, here it is. The SDE discovers the plugin .json environment descriptors in the file system tree. Once they're disocvered, they're passed to the Plugin Manager which loads each of them and puts them into the appropriate structure. Once they're in there, they are requested by UefiBuild or MuBuild and dispatched. Helper functions are requested from the PluginManager and then executed. Writing your own \u00b6 Writing your own plugin is fairly simple. See MuEnvironment\\PluginManager.py for the interface definition and required functions for each type of plugin. For IUefiBuildPlugin type the plugin will simply be called during the pre and post build steps after the platform builder object runs its step. The UefiBuilder object will be passed during the call and therefore the environment dictionary is available within the plugin. These plugins should be authored to be independent and the platform build or UEFI build should not have any dependency on the plugin. The plugin can depend on variables within the environment dictionary but should be otherwise independent / isolated code. For IUefiHelperPlugin type the plugin will simply register functions with the helper object so that other parts of the platform build can use the functions. It is acceptable for platform build to know/need the helper functions but it is not acceptable for UEFI build super class to depend upon it. I expect most of these plugins will be at a layer lower than the UDK as this is really to isolate business unit logic while still allowing code reuse. Look at the HelperFunctions object to see how a plugin registers its functions. For IMuBuildPlugin type the plugin will be allowed to verify it's configuration and be called by the MuBuild system. It will have the current state of the build and access to the environment. MuBuild checkpoints the environment prior to calling out to each plugin, so the environment can be dirtied by the plugin. As an example of a Mu Build Plugin, we will look at one of the plugins we use, Character Encoding Check MuBuildPlugin. This runs as part of the MuBuild CI build. The schema \u00b6 From MU_BASECORE\\BaseTools\\Plugin\\CharEncodingCheck\\CharEncodingCheck_plug_in.json { \"scope\" : \"project_mu\" , \"name\" : \"Char Encoding Check Test\" , \"module\" : \"CharEncodingCheck\" } Scope: See the SDE doc about scopes Name: This is the name of the plugin and will be part of the path where the nuget is unpacked Module: the python file to load The Python \u00b6 File is from: MU_BASECORE\\BaseTools\\Plugin\\CharEncodingCheck\\CharEncodingCheck.py It's important that the filename matches the Module name in the json file. import os import logging from MuEnvironment.PluginManager import IMuBuildPlugin class CharEncodingCheck ( IMuBuildPlugin ): def GetTestName ( self , packagename , environment ): return ( \"MuBuild CharEncodingCheck \" + packagename , \"MuBuild.CharEncodingCheck.\" + packagename ) # - package is the edk2 path to package. This means workspace/packagepath relative. # - edk2path object configured with workspace and packages path # - any additional command line args # - RepoConfig Object (dict) for the build # - PkgConfig Object (dict) for the pkg # - EnvConfig Object # - Plugin Manager Instance # - Plugin Helper Obj Instance # - testclass Object used for outputing junit results # - output_stream the StringIO output stream from this plugin def RunBuildPlugin ( self , packagename , Edk2pathObj , args , repoconfig , pkgconfig , environment , PLM , PLMHelper , tc , output_stream = None ): overall_status = 0 files_tested = 0 if overall_status is not 0 : tc . SetFailed ( \"CharEncoding {0} Failed. Errors {1}\" . format ( packagename , overall_status ), \"CHAR_ENCODING_CHECK_FAILED\" ) else : tc . SetSuccess () return overall_status def ValidateConfig ( self , config , name ): validOptions = [ \"IgnoreFiles\" , \"skip\" ] for key in config : if key not in validOptions : raise Exception ( \"Invalid config option {0} in {1}\" . format ( key , name )) Some things to notice are the class that this is inheriting from: IMuBuildPlugin. Validate Config is the way that a plugin can validate the configuration they will receive. The repo config and the package config is later passed into the RunBuildPlugin method. The validate step is run before build happens so we don't waste a user's time only to bail halfway through the build process. There is also this idea of the tc, which is the test unit class. You can set this particular MuBuild step as failed, skipped, or successful. Logging standard out or error out gets placed in the JUnit report that is later picked up by the CI system. Using a plugin \u00b6 Using plugins is straightforward but it exact usage depends on what type of plugin you use. For the IUefiBuildPlugin (pre/post build) and IMuBuildPlugin type there is nothing the UEFI build must do besides make sure the plugin is in your workspace and scoped to an active scope. For Helper plugins basically the UEFI builder Helper member will contain the registered functions as methods on the object. Therefore calling any function is as simple as using self.Helper.[your func name here]. It is by design that the parameters and calling contract are not defined. It is expected that the caller and plugin know about each other and are really just using the plugin system to make inclusion and code sharing easy.","title":"feature pluginmanager"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/#plugin-manager","text":"","title":"Plugin Manager"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/#the-genesis","text":"Plugins are similar to external dependencies, in that they are defined by a Json file and they are discovered by the SDE. If you wish to learn more about the SDE, please go read the document about the self describing enviroment. They are defined by the EnvironmentDescriptorFiles which also describe external dependencies and path descriptors.","title":"The Genesis"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/#types-of-plugins","text":"Types of plugins are defined by the class they inherit from UefiBuildPlugin Contains two methods, Pre and Post Build. These methods are called on Pre and Post Build steps in UefiBuild (not MuBuild). There is no guarantee on ordering between different plugins (Pre will always come before Post). Post is will not run if there is a critical error in the build process. The idea here is to allow for custom, self-contained build functionality to be added without required UEFI build changes or inline code modifications. DscProcessorPlugin (in-progress) This is a plugin type that can apply transformations to the active DSC that will then be used to build the system. This is not production ready and not enabled in any builds currently. UefiHelperPlugin This is a helper plugin that publishes a function that can be used by other parts of the system. An example of this would be the Capsule signing system. This really is less about plugin design and more about keeping the UEFI build and platform builder python files minimal and getting the desired code reuse. MuBuildPlugin A plugin that runs during the main stage of MuBuild. The build step is actually a plugin so as ordering is not guranteed so you don't have any assurance that the build is successful or that the build has started","title":"Types of plugins"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/#how-it-works","text":"You might be asking yourself how does the sausage get made. In the name of sating curiosity, here it is. The SDE discovers the plugin .json environment descriptors in the file system tree. Once they're disocvered, they're passed to the Plugin Manager which loads each of them and puts them into the appropriate structure. Once they're in there, they are requested by UefiBuild or MuBuild and dispatched. Helper functions are requested from the PluginManager and then executed.","title":"How it works"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/#writing-your-own","text":"Writing your own plugin is fairly simple. See MuEnvironment\\PluginManager.py for the interface definition and required functions for each type of plugin. For IUefiBuildPlugin type the plugin will simply be called during the pre and post build steps after the platform builder object runs its step. The UefiBuilder object will be passed during the call and therefore the environment dictionary is available within the plugin. These plugins should be authored to be independent and the platform build or UEFI build should not have any dependency on the plugin. The plugin can depend on variables within the environment dictionary but should be otherwise independent / isolated code. For IUefiHelperPlugin type the plugin will simply register functions with the helper object so that other parts of the platform build can use the functions. It is acceptable for platform build to know/need the helper functions but it is not acceptable for UEFI build super class to depend upon it. I expect most of these plugins will be at a layer lower than the UDK as this is really to isolate business unit logic while still allowing code reuse. Look at the HelperFunctions object to see how a plugin registers its functions. For IMuBuildPlugin type the plugin will be allowed to verify it's configuration and be called by the MuBuild system. It will have the current state of the build and access to the environment. MuBuild checkpoints the environment prior to calling out to each plugin, so the environment can be dirtied by the plugin. As an example of a Mu Build Plugin, we will look at one of the plugins we use, Character Encoding Check MuBuildPlugin. This runs as part of the MuBuild CI build.","title":"Writing your own"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/#the-schema","text":"From MU_BASECORE\\BaseTools\\Plugin\\CharEncodingCheck\\CharEncodingCheck_plug_in.json { \"scope\" : \"project_mu\" , \"name\" : \"Char Encoding Check Test\" , \"module\" : \"CharEncodingCheck\" } Scope: See the SDE doc about scopes Name: This is the name of the plugin and will be part of the path where the nuget is unpacked Module: the python file to load","title":"The schema"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/#the-python","text":"File is from: MU_BASECORE\\BaseTools\\Plugin\\CharEncodingCheck\\CharEncodingCheck.py It's important that the filename matches the Module name in the json file. import os import logging from MuEnvironment.PluginManager import IMuBuildPlugin class CharEncodingCheck ( IMuBuildPlugin ): def GetTestName ( self , packagename , environment ): return ( \"MuBuild CharEncodingCheck \" + packagename , \"MuBuild.CharEncodingCheck.\" + packagename ) # - package is the edk2 path to package. This means workspace/packagepath relative. # - edk2path object configured with workspace and packages path # - any additional command line args # - RepoConfig Object (dict) for the build # - PkgConfig Object (dict) for the pkg # - EnvConfig Object # - Plugin Manager Instance # - Plugin Helper Obj Instance # - testclass Object used for outputing junit results # - output_stream the StringIO output stream from this plugin def RunBuildPlugin ( self , packagename , Edk2pathObj , args , repoconfig , pkgconfig , environment , PLM , PLMHelper , tc , output_stream = None ): overall_status = 0 files_tested = 0 if overall_status is not 0 : tc . SetFailed ( \"CharEncoding {0} Failed. Errors {1}\" . format ( packagename , overall_status ), \"CHAR_ENCODING_CHECK_FAILED\" ) else : tc . SetSuccess () return overall_status def ValidateConfig ( self , config , name ): validOptions = [ \"IgnoreFiles\" , \"skip\" ] for key in config : if key not in validOptions : raise Exception ( \"Invalid config option {0} in {1}\" . format ( key , name )) Some things to notice are the class that this is inheriting from: IMuBuildPlugin. Validate Config is the way that a plugin can validate the configuration they will receive. The repo config and the package config is later passed into the RunBuildPlugin method. The validate step is run before build happens so we don't waste a user's time only to bail halfway through the build process. There is also this idea of the tc, which is the test unit class. You can set this particular MuBuild step as failed, skipped, or successful. Logging standard out or error out gets placed in the JUnit report that is later picked up by the CI system.","title":"The Python"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_pluginmanager/#using-a-plugin","text":"Using plugins is straightforward but it exact usage depends on what type of plugin you use. For the IUefiBuildPlugin (pre/post build) and IMuBuildPlugin type there is nothing the UEFI build must do besides make sure the plugin is in your workspace and scoped to an active scope. For Helper plugins basically the UEFI builder Helper member will contain the registered functions as methods on the object. Therefore calling any function is as simple as using self.Helper.[your func name here]. It is by design that the parameters and calling contract are not defined. It is expected that the caller and plugin know about each other and are really just using the plugin system to make inclusion and code sharing easy.","title":"Using a plugin"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/","text":"The Self Describing Environment and You \u00b6 The Genesis \u00b6 As Project Mu grew, the centralized systems that have been in place to this point have gotten more and more brittle. Previously, the paths to critical files and build tools have been hard-coded into the primary build scripts (such as PlatformBuild.py). If code was to be added or moved, all build scripts for all projects had to be updated to find the new code and consume it. Furthermore, the old build system required that all binaries, executables, artifacts, and other miscellaneous files be carried in the source tree somewhere. Since moving to Git, this cost has become increasingly burdensome to the point where some of the larger repos are almost unwieldly. The new Self Describing Environment system, along with the new Plugin behavior, aims to remedy some of these problems, while preserving flexibility and agility for further project growth. What is it? \u00b6 The Self-Describing Environment is assembled by a combination of scripts and descriptor files. The scripts locate the descriptor files and configure the environment in a number of different ways (eg. PATH, PYTHONPATH, Shell Variables, Build Variables, external dependencies, etc.). Currently, there are two kinds of descriptor files that can be found in the Core UEFI tree: Path Environment descriptors (path_env) and External Dependency descriptors (ext_dep). Both of these files are simple JSON files containing fields that are used to configure the SDE. They have some overlapping features, but are used for very different purposes. Many of these features have their own documentation, and you are encouraged to go check them out. path_env Descriptors \u00b6 The path_env descriptor is used, primarily, to update the path. This way the build system can locate required tools and scripts. It can also update build vars that can be referenced from the primary build script (PlatformBuild.py) to locate things like binary artifacts that will be included in certain build steps (eg. OPROM binaries). The path_env descriptor works by taking the path containing the descriptor and applying it to the environment as specified by the fields of the descriptor. For example, if there were a path_env file located at \"\\MyBuild\\SubDir\\Tools\\my_sample_path_env.json\" and the descriptor flags included \"set_path\", \"\\MyBuild\\SubDir\\Tools\" would be added to the environment path. path_env descriptors are located by the environment configuration scripts by searching the Workspace for files ending in \"*_path_env.json\". It does not matter what the first part of the file is called, so long as the end is correct. By convention, the first part of the file name should be descriptive enough to differentiate a given descriptor from another descriptor, should it show up in a \"find in files\" list or something. The following path_env fields are required: scope Identifies which build environments this descriptor contributes to, and what level of precedence it should take within that environment. flags We'll see that flags are common to both path_env and ext_dep descriptors, but they are required for path_env (and only optional for ext_dep). This is because it doesn\u2019t make any sense to create a path_env descriptor without specifying what part of the environment should be updated. Currently supported flags are: host_specific Allows a nuget package to specify that the contents of the package are organized by host OS or architecture. The SDE will determine what folder is relevant for the host OS and product being built and add that to the path. set_path Adds the NuGet unpacked folder to the front of PATH set_pypath Adds the NuGet unpacked folder to the front of PYTHONPATH. Also adds it to sys.path. set_build_var Sets a build variable with the key being the name of the ext_dep and the value being the path of the nuget unpacked folder If you include this attribute you must include a var_name (a var that exists internally to the build system that is retrieved with with env.GetValue()) set_shell_var Sets a shell variable with the key being the name of the ext_dep and the value being the path of the nuget unpacked folder If you include this attribute you must include a var_name (a var that exists in the command-line environment via \"set\" or \"os.environ\" or \"env\") include_separator Includes a path seperated at the end of the path we set in variables The following path_env fields are optional or conditional: var_name If either the \"set_shell_var\" or \"set_build_var\" are in the flags, this field will be required. It defines the name of the var being set. id Part of the Override System, this field defines the name that this file will be referred to as by any override_id fields. override_id This file will override any descriptor files found in lower lexical order or scope order. Files are traversed in directory order (depth first) and then scope order (highest to lowest). Overrides are only applied forward in the traversal, not backwards. The Belly of the Beast \u00b6 SelfDescribingEnvironment.py \u00b6 This is the proverbial \"heart of the beast\". It contains most of the business logic for locating, compiling, sorting, filtering, and assembling the SDE files and the environment itself. There are class methods and helper functions to do things like: - Locate all the relevant files in the workspace. - Sort the files lexically and by scope. - Filter the files based on overrides. - Assemble the environment (eg. PATH, PYTHONPATH, vars, etc.). - Validate all dependencies. - Update all dependencies. Many of these routines will leverage logic specific to individual sub-modules (Python, not Git), but the collective logic is located here. EnvironmentDescriptorFiles.py \u00b6 This module contains business logic and validation code for dealing with the descriptor files as JSON objects. It contains code (and error checking) for loading the files, reading their contents into a standard internal representation, and running a limited set of sanitization and validation functions to identify any mistakes as early as possible and provide as much information as possible. For convenience, this module also contains the class code for PathEnv descriptor objects, but that's because the class code is so small felt silly to create another file. ExternalDependencies.py \u00b6 This module contains code for managing external dependencies. ExternalDependency objects are created with the data from ext_dep descriptors and are subclassed according to the \"type\" field in the descriptor. Currently, the only valid subclass is \"nuget\". These objects contain the code for fetching, validating, updating, and cleaning dependency objects and metadata. When referenced from the SDE itself, they can also update paths and other build/shell vars in the build environment. Taming the SDE \u00b6 Understanding Scope \u00b6 A critical concept in the SDE system is that of \"scope\". Each project can define its own scope, and scope is integral to the distributed and shared nature of the SDE. Project scopes are linearly hierarchical and can have an arbitrary number of entries. Only descriptors matching one or more of the scope entries will be included in the SDE during initialization. Furthermore, higher scopes will take precedence when setting paths and assigning values to vars. An example project scope might be: (\"my_platform\", \"tablet_family\", \"silicon_reference\") In this example, \"my_platform\" is the highest priority in the scope. Any descriptor files found in the entire workspace that have this scope will not only be included in the SDE, they will take precedence over any of the lesser scopes. \"tablet_family\" and \"silicon_reference\" scopes will also be used, in that order. Additionally, all projects inherit the \"global\" scope, but it takes the lowest precedence. Setting Up for PlatformBuild \u00b6 The SDE includes modifications to the PlatformBuild.py script that make it easier to start working with any platform. Since the SDE knows how to fetch its own dependencies, and since all these dependencies are described by the platform itself, the build scripts can now perform the minimal steps to enable building any given platform, including: Synchronizing all required submodules. Downloading all source (and only the source actually used by the platform). Configuring all paths. Downloading all binaries. To leverage this setup behavior, simply run the PlatformBuild.py script corresponding to the platform you want to build with the \"--SETUP\" argument. This argument will cause the platform to configure itself, and display any errors encountered. NOTE: --SETUP should only be required once per build machine, per platform being built. It is not necessary to run it regularly. Only when setting up a new personal workstation or starting to work with a platform that you haven't used yet. The --SETUP feature does not actually build the platform. A normal PlatformBuild.py must still be performed. The --SETUP feature will NOT change branches in any submodule that already exists locally, or that has local changes. This is to prevent accidental loss of work. If you would like the script to try making changes even in these cases, use the \"--FORCE\" argument. The --SETUP feature does not yet install dev singing certs. Those steps must still be performed manually. Setting Up for MuBuild \u00b6 MuBuild works on a similar mechanism to PlatformBuild but it invokes the SDE directly and does an update. Git Modules are monitored and handled via the RepoResolver framework, which has more logic to it, and doesn't handle submodules.c Building \u00b6 Building still works as it always has and all prior arguments can still be passed to the PlatformBuild.py script. The only special arguments are \"--SETUP\" and \"--UPDATE\" (described below), which will trigger new behaviors. Note that the current state of the SDE is always printed in the DEBUG level of the build log. Updating Dependencies \u00b6 Prior to any build, the SDE will attempt to validate the external dependencies that currently exist on the local machine against the versions that are specified in the code. If the code is updated (perhaps by a pull request to the branch you're working on), it is possible that the dependencies will have to be refreshed. If this is the case, you will see a message prompting you to do so when you run PlatformBuild.py to build your platform. To perform this update, simply run the PlatformBuild.py script with the --UPDATE argument. Any dependencies that match their current versions will be skipped and only out-of-date dependencies will be refreshed.","title":"feature sde"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#the-self-describing-environment-and-you","text":"","title":"The Self Describing Environment and You"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#the-genesis","text":"As Project Mu grew, the centralized systems that have been in place to this point have gotten more and more brittle. Previously, the paths to critical files and build tools have been hard-coded into the primary build scripts (such as PlatformBuild.py). If code was to be added or moved, all build scripts for all projects had to be updated to find the new code and consume it. Furthermore, the old build system required that all binaries, executables, artifacts, and other miscellaneous files be carried in the source tree somewhere. Since moving to Git, this cost has become increasingly burdensome to the point where some of the larger repos are almost unwieldly. The new Self Describing Environment system, along with the new Plugin behavior, aims to remedy some of these problems, while preserving flexibility and agility for further project growth.","title":"The Genesis"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#what-is-it","text":"The Self-Describing Environment is assembled by a combination of scripts and descriptor files. The scripts locate the descriptor files and configure the environment in a number of different ways (eg. PATH, PYTHONPATH, Shell Variables, Build Variables, external dependencies, etc.). Currently, there are two kinds of descriptor files that can be found in the Core UEFI tree: Path Environment descriptors (path_env) and External Dependency descriptors (ext_dep). Both of these files are simple JSON files containing fields that are used to configure the SDE. They have some overlapping features, but are used for very different purposes. Many of these features have their own documentation, and you are encouraged to go check them out.","title":"What is it?"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#path_env-descriptors","text":"The path_env descriptor is used, primarily, to update the path. This way the build system can locate required tools and scripts. It can also update build vars that can be referenced from the primary build script (PlatformBuild.py) to locate things like binary artifacts that will be included in certain build steps (eg. OPROM binaries). The path_env descriptor works by taking the path containing the descriptor and applying it to the environment as specified by the fields of the descriptor. For example, if there were a path_env file located at \"\\MyBuild\\SubDir\\Tools\\my_sample_path_env.json\" and the descriptor flags included \"set_path\", \"\\MyBuild\\SubDir\\Tools\" would be added to the environment path. path_env descriptors are located by the environment configuration scripts by searching the Workspace for files ending in \"*_path_env.json\". It does not matter what the first part of the file is called, so long as the end is correct. By convention, the first part of the file name should be descriptive enough to differentiate a given descriptor from another descriptor, should it show up in a \"find in files\" list or something. The following path_env fields are required: scope Identifies which build environments this descriptor contributes to, and what level of precedence it should take within that environment. flags We'll see that flags are common to both path_env and ext_dep descriptors, but they are required for path_env (and only optional for ext_dep). This is because it doesn\u2019t make any sense to create a path_env descriptor without specifying what part of the environment should be updated. Currently supported flags are: host_specific Allows a nuget package to specify that the contents of the package are organized by host OS or architecture. The SDE will determine what folder is relevant for the host OS and product being built and add that to the path. set_path Adds the NuGet unpacked folder to the front of PATH set_pypath Adds the NuGet unpacked folder to the front of PYTHONPATH. Also adds it to sys.path. set_build_var Sets a build variable with the key being the name of the ext_dep and the value being the path of the nuget unpacked folder If you include this attribute you must include a var_name (a var that exists internally to the build system that is retrieved with with env.GetValue()) set_shell_var Sets a shell variable with the key being the name of the ext_dep and the value being the path of the nuget unpacked folder If you include this attribute you must include a var_name (a var that exists in the command-line environment via \"set\" or \"os.environ\" or \"env\") include_separator Includes a path seperated at the end of the path we set in variables The following path_env fields are optional or conditional: var_name If either the \"set_shell_var\" or \"set_build_var\" are in the flags, this field will be required. It defines the name of the var being set. id Part of the Override System, this field defines the name that this file will be referred to as by any override_id fields. override_id This file will override any descriptor files found in lower lexical order or scope order. Files are traversed in directory order (depth first) and then scope order (highest to lowest). Overrides are only applied forward in the traversal, not backwards.","title":"path_env Descriptors"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#the-belly-of-the-beast","text":"","title":"The Belly of the Beast"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#selfdescribingenvironmentpy","text":"This is the proverbial \"heart of the beast\". It contains most of the business logic for locating, compiling, sorting, filtering, and assembling the SDE files and the environment itself. There are class methods and helper functions to do things like: - Locate all the relevant files in the workspace. - Sort the files lexically and by scope. - Filter the files based on overrides. - Assemble the environment (eg. PATH, PYTHONPATH, vars, etc.). - Validate all dependencies. - Update all dependencies. Many of these routines will leverage logic specific to individual sub-modules (Python, not Git), but the collective logic is located here.","title":"SelfDescribingEnvironment.py"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#environmentdescriptorfilespy","text":"This module contains business logic and validation code for dealing with the descriptor files as JSON objects. It contains code (and error checking) for loading the files, reading their contents into a standard internal representation, and running a limited set of sanitization and validation functions to identify any mistakes as early as possible and provide as much information as possible. For convenience, this module also contains the class code for PathEnv descriptor objects, but that's because the class code is so small felt silly to create another file.","title":"EnvironmentDescriptorFiles.py"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#externaldependenciespy","text":"This module contains code for managing external dependencies. ExternalDependency objects are created with the data from ext_dep descriptors and are subclassed according to the \"type\" field in the descriptor. Currently, the only valid subclass is \"nuget\". These objects contain the code for fetching, validating, updating, and cleaning dependency objects and metadata. When referenced from the SDE itself, they can also update paths and other build/shell vars in the build environment.","title":"ExternalDependencies.py"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#taming-the-sde","text":"","title":"Taming the SDE"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#understanding-scope","text":"A critical concept in the SDE system is that of \"scope\". Each project can define its own scope, and scope is integral to the distributed and shared nature of the SDE. Project scopes are linearly hierarchical and can have an arbitrary number of entries. Only descriptors matching one or more of the scope entries will be included in the SDE during initialization. Furthermore, higher scopes will take precedence when setting paths and assigning values to vars. An example project scope might be: (\"my_platform\", \"tablet_family\", \"silicon_reference\") In this example, \"my_platform\" is the highest priority in the scope. Any descriptor files found in the entire workspace that have this scope will not only be included in the SDE, they will take precedence over any of the lesser scopes. \"tablet_family\" and \"silicon_reference\" scopes will also be used, in that order. Additionally, all projects inherit the \"global\" scope, but it takes the lowest precedence.","title":"Understanding Scope"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#setting-up-for-platformbuild","text":"The SDE includes modifications to the PlatformBuild.py script that make it easier to start working with any platform. Since the SDE knows how to fetch its own dependencies, and since all these dependencies are described by the platform itself, the build scripts can now perform the minimal steps to enable building any given platform, including: Synchronizing all required submodules. Downloading all source (and only the source actually used by the platform). Configuring all paths. Downloading all binaries. To leverage this setup behavior, simply run the PlatformBuild.py script corresponding to the platform you want to build with the \"--SETUP\" argument. This argument will cause the platform to configure itself, and display any errors encountered. NOTE: --SETUP should only be required once per build machine, per platform being built. It is not necessary to run it regularly. Only when setting up a new personal workstation or starting to work with a platform that you haven't used yet. The --SETUP feature does not actually build the platform. A normal PlatformBuild.py must still be performed. The --SETUP feature will NOT change branches in any submodule that already exists locally, or that has local changes. This is to prevent accidental loss of work. If you would like the script to try making changes even in these cases, use the \"--FORCE\" argument. The --SETUP feature does not yet install dev singing certs. Those steps must still be performed manually.","title":"Setting Up for PlatformBuild"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#setting-up-for-mubuild","text":"MuBuild works on a similar mechanism to PlatformBuild but it invokes the SDE directly and does an update. Git Modules are monitored and handled via the RepoResolver framework, which has more logic to it, and doesn't handle submodules.c","title":"Setting Up for MuBuild"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#building","text":"Building still works as it always has and all prior arguments can still be passed to the PlatformBuild.py script. The only special arguments are \"--SETUP\" and \"--UPDATE\" (described below), which will trigger new behaviors. Note that the current state of the SDE is always printed in the DEBUG level of the build log.","title":"Building"},{"location":"dyn/mu_pip_environment/MuEnvironment/docs/feature_sde/#updating-dependencies","text":"Prior to any build, the SDE will attempt to validate the external dependencies that currently exist on the local machine against the versions that are specified in the code. If the code is updated (perhaps by a pull request to the branch you're working on), it is possible that the dependencies will have to be refreshed. If this is the case, you will see a message prompting you to do so when you run PlatformBuild.py to build your platform. To perform this update, simply run the PlatformBuild.py script with the --UPDATE argument. Any dependencies that match their current versions will be skipped and only out-of-date dependencies will be refreshed.","title":"Updating Dependencies"},{"location":"dyn/mu_pip_python_library/RepoDetails/","text":"Project Mu Pip Python Library \u00b6 Git Details Repository Url: https://github.com/Microsoft/mu_pip_python_library.git Branch: master Commit: 0cc4d5418b8436807d840cbcabaaeca3f6d6ebc5 Commit Date: 2019-07-08 21:53:16 +0000 Python files describing various miscellaneous components from the TPM and EDKII specs. More Info \u00b6 Please see the Project Mu docs ( https://github.com/Microsoft/mu ) for more information. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Issues \u00b6 Please open any issues in the Project Mu GitHub tracker. More Details Contributing Code or Docs \u00b6 Please follow the general Project Mu Pull Request process. More Details Additionally make sure all testing described in the \"Development\" section passes. Using \u00b6 Usage Details Development \u00b6 Development Details Publish \u00b6 Publish Details Copyright & License \u00b6 Copyright \u00a9 2016-2018, Microsoft Corporation All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Repo Details"},{"location":"dyn/mu_pip_python_library/RepoDetails/#project-mu-pip-python-library","text":"Git Details Repository Url: https://github.com/Microsoft/mu_pip_python_library.git Branch: master Commit: 0cc4d5418b8436807d840cbcabaaeca3f6d6ebc5 Commit Date: 2019-07-08 21:53:16 +0000 Python files describing various miscellaneous components from the TPM and EDKII specs.","title":"Project Mu Pip Python Library"},{"location":"dyn/mu_pip_python_library/RepoDetails/#more-info","text":"Please see the Project Mu docs ( https://github.com/Microsoft/mu ) for more information. This project has adopted the Microsoft Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.","title":"More Info"},{"location":"dyn/mu_pip_python_library/RepoDetails/#issues","text":"Please open any issues in the Project Mu GitHub tracker. More Details","title":"Issues"},{"location":"dyn/mu_pip_python_library/RepoDetails/#contributing-code-or-docs","text":"Please follow the general Project Mu Pull Request process. More Details Additionally make sure all testing described in the \"Development\" section passes.","title":"Contributing Code or Docs"},{"location":"dyn/mu_pip_python_library/RepoDetails/#using","text":"Usage Details","title":"Using"},{"location":"dyn/mu_pip_python_library/RepoDetails/#development","text":"Development Details","title":"Development"},{"location":"dyn/mu_pip_python_library/RepoDetails/#publish","text":"Publish Details","title":"Publish"},{"location":"dyn/mu_pip_python_library/RepoDetails/#copyright-license","text":"Copyright \u00a9 2016-2018, Microsoft Corporation All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"Copyright &amp; License"},{"location":"dyn/mu_pip_python_library/developing/","text":"Developing Project Mu Pip Python Library \u00b6 Pre-Requisites \u00b6 Get the code git clone https : // github . com / Microsoft / mu_pip_python_library . git Install development dependencies pip install --upgrade -r requirements.txt Uninstall any copy of mu_python_library pip uninstall mu_python_library Install from local source (run command from root of repo) pip install - e . Testing \u00b6 Run a Basic Syntax/Lint Check (using flake8) and resolve any issues flake8 MuPythonLibrary Info Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run pytest with coverage data collected pytest - v --junitxml=test.junit.xml --html=pytest_MuPythonLibrary_report.html --self-contained-html --cov=MuPythonLibrary --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_MuPythonLibrary_report.html cov_html/index.html","title":"developing"},{"location":"dyn/mu_pip_python_library/developing/#developing-project-mu-pip-python-library","text":"","title":"Developing Project Mu Pip Python Library"},{"location":"dyn/mu_pip_python_library/developing/#pre-requisites","text":"Get the code git clone https : // github . com / Microsoft / mu_pip_python_library . git Install development dependencies pip install --upgrade -r requirements.txt Uninstall any copy of mu_python_library pip uninstall mu_python_library Install from local source (run command from root of repo) pip install - e .","title":"Pre-Requisites"},{"location":"dyn/mu_pip_python_library/developing/#testing","text":"Run a Basic Syntax/Lint Check (using flake8) and resolve any issues flake8 MuPythonLibrary Info Newer editors are very helpful in resolving source formatting errors (whitespace, indentation, etc). In VSCode open the py file and use ++alt+shift+f++ to auto format. Run pytest with coverage data collected pytest - v --junitxml=test.junit.xml --html=pytest_MuPythonLibrary_report.html --self-contained-html --cov=MuPythonLibrary --cov-report html:cov_html --cov-report xml:cov.xml --cov-config .coveragerc Look at the reports pytest_MuPythonLibrary_report.html cov_html/index.html","title":"Testing"},{"location":"dyn/mu_pip_python_library/publishing/","text":"Publishing Project Mu Pip Python Library \u00b6 The MuPythonLibrary is published as a pypi (pip) module. The pip module is named mu_python_library . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here. Steps \u00b6 Info These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and check. Update the readme with info on changes for this version. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released. Tag format is v . . Do the release process Install tools pip install --upgrade -r requirements.publisher.txt Build a wheel python setup . py sdist bdist_wheel Confirm wheel version is aligned with git tag ConfirmVersionAndTag . py Publish the wheel/distribution to pypi twine upload dist /*","title":"publishing"},{"location":"dyn/mu_pip_python_library/publishing/#publishing-project-mu-pip-python-library","text":"The MuPythonLibrary is published as a pypi (pip) module. The pip module is named mu_python_library . Pypi allows for easy version management, dependency management, and sharing. Publishing/releasing a new version is generally handled thru a server based build process but for completeness the process is documented here.","title":"Publishing Project Mu Pip Python Library"},{"location":"dyn/mu_pip_python_library/publishing/#steps","text":"Info These directions assume you have already configured your workspace for developing. If not please first do that. Directions on the developing page. Pass all development tests and check. Update the readme with info on changes for this version. Get your changes into master branch (official releases should only be done from the master branch) Make a git tag for the version that will be released. Tag format is v . . Do the release process Install tools pip install --upgrade -r requirements.publisher.txt Build a wheel python setup . py sdist bdist_wheel Confirm wheel version is aligned with git tag ConfirmVersionAndTag . py Publish the wheel/distribution to pypi twine upload dist /*","title":"Steps"},{"location":"dyn/mu_pip_python_library/using/","text":"Using Project Mu Pip Python Library \u00b6 Install from pip pip install mu_python_library Usage Docs \u00b6 TBD","title":"using"},{"location":"dyn/mu_pip_python_library/using/#using-project-mu-pip-python-library","text":"Install from pip pip install mu_python_library","title":"Using Project Mu Pip Python Library"},{"location":"dyn/mu_pip_python_library/using/#usage-docs","text":"TBD","title":"Usage Docs"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_GetHostInfo/","text":"GetHostInfo \u00b6 This document details the utility function called GetHostInfo. This function was written because NuGet needed a way to determine attributes about the host system to determine what parts of a dependency to use. How to Use \u00b6 from MuPythonLibrary.UtilityFunctions import GetHostInfo host_info = GetHostInfo () Usage info \u00b6 GetHostInfo() will return a namedtuple with 3 attributes describing the host machine. Below for each is the name of the field, description of the field and possible contents therein. 1. os - OS Name \u00b6 Windows, Linux, or Java 2. arch - Processor architecture \u00b6 ARM or x86 3. bit - Highest order bit \u00b6 32 or 64 Purpose \u00b6 Since there are multiple different ways one could derive these values, it is necessary provide a common implementation of that logic to ensure it is uniform.","title":"feature Get Host Info"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_GetHostInfo/#gethostinfo","text":"This document details the utility function called GetHostInfo. This function was written because NuGet needed a way to determine attributes about the host system to determine what parts of a dependency to use.","title":"GetHostInfo"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_GetHostInfo/#how-to-use","text":"from MuPythonLibrary.UtilityFunctions import GetHostInfo host_info = GetHostInfo ()","title":"How to Use"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_GetHostInfo/#usage-info","text":"GetHostInfo() will return a namedtuple with 3 attributes describing the host machine. Below for each is the name of the field, description of the field and possible contents therein.","title":"Usage info"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_GetHostInfo/#1-os-os-name","text":"Windows, Linux, or Java","title":"1. os - OS Name"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_GetHostInfo/#2-arch-processor-architecture","text":"ARM or x86","title":"2. arch - Processor architecture"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_GetHostInfo/#3-bit-highest-order-bit","text":"32 or 64","title":"3. bit - Highest order bit"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_GetHostInfo/#purpose","text":"Since there are multiple different ways one could derive these values, it is necessary provide a common implementation of that logic to ensure it is uniform.","title":"Purpose"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/","text":"GetHostInfo \u00b6 This document details the Ansi Handler How to Use \u00b6 from MuPythonLibrary.MuAnsiHandler import ColoredStreamHandler handler = ColoredStreamHandler ( stream , strip = True , convert = False ) formatter = ColoredFormatter () Usage info \u00b6 ColoredStreamHandler() will create a handler from the logging package. It accepts a stream (such as a file) and will display the colors in that particular stream as needed to the console. There are two options, strip and convert. ColoredFormatter() will create a formater from the logging package that will insert ANSI codes according to the logging level into the output stream. ColoredStreamHandler Arguments \u00b6 1. strip \u00b6 Strip will strip ANSI codes if the terminal does not support them (such as windows). 2. convert \u00b6 Convert will convert ANSI codes on windows platforms into windows platform calls. ColoredFormatter Arguments \u00b6 1. msg \u00b6 The best documentation for this is from Python itself. It's the same message that's passed into the Formatted baseclass. 2. use_azure \u00b6 Azure Dev ops can support colors with certain keywords. This turns that on instead of using ANSI. Purpose \u00b6 To put color into your life and your terminal, we needed to support coloring based on logging levels. ANSI seemed like a universal choice. The StreamHandler is just a workaround for windows based systems that don't support ANSI natively.","title":"feature Mu Ansi Handler"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#gethostinfo","text":"This document details the Ansi Handler","title":"GetHostInfo"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#how-to-use","text":"from MuPythonLibrary.MuAnsiHandler import ColoredStreamHandler handler = ColoredStreamHandler ( stream , strip = True , convert = False ) formatter = ColoredFormatter ()","title":"How to Use"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#usage-info","text":"ColoredStreamHandler() will create a handler from the logging package. It accepts a stream (such as a file) and will display the colors in that particular stream as needed to the console. There are two options, strip and convert. ColoredFormatter() will create a formater from the logging package that will insert ANSI codes according to the logging level into the output stream.","title":"Usage info"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#coloredstreamhandler-arguments","text":"","title":"ColoredStreamHandler Arguments"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#1-strip","text":"Strip will strip ANSI codes if the terminal does not support them (such as windows).","title":"1. strip"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#2-convert","text":"Convert will convert ANSI codes on windows platforms into windows platform calls.","title":"2. convert"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#coloredformatter-arguments","text":"","title":"ColoredFormatter Arguments"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#1-msg","text":"The best documentation for this is from Python itself. It's the same message that's passed into the Formatted baseclass.","title":"1. msg"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#2-use_azure","text":"Azure Dev ops can support colors with certain keywords. This turns that on instead of using ANSI.","title":"2. use_azure"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/feature_MuAnsiHandler/#purpose","text":"To put color into your life and your terminal, we needed to support coloring based on logging levels. ANSI seemed like a universal choice. The StreamHandler is just a workaround for windows based systems that don't support ANSI natively.","title":"Purpose"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/bin/vswhere/","text":"This is where VSwhere will go? \u00b6","title":"bin"},{"location":"dyn/mu_pip_python_library/MuPythonLibrary/bin/vswhere/#this-is-where-vswhere-will-go","text":"","title":"This is where VSwhere will go?"}]}